{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58e2e31-b886-4a63-b4da-b44b6c65030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.export import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5991d004-4ab0-4c9e-9613-06491ab3715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExportedProgram:\n",
      "    class GraphModule(torch.nn.Module):\n",
      "        def forward(self, arg0_1: f32[20, 10], arg1_1: f32[20], arg2_1: f32[2, 10]):\n",
      "            # \n",
      "            permute: f32[10, 20] = torch.ops.aten.permute.default(arg0_1, [1, 0]);  arg0_1 = None\n",
      "            addmm: f32[2, 20] = torch.ops.aten.addmm.default(arg1_1, arg2_1, permute);  arg1_1 = arg2_1 = permute = None\n",
      "            return (addmm,)\n",
      "            \n",
      "Graph Signature: ExportGraphSignature(parameters=['L__self___layer.weight', 'L__self___layer.bias'], buffers=[], user_inputs=['arg2_1'], user_outputs=['addmm'], inputs_to_parameters={'arg0_1': 'L__self___layer.weight', 'arg1_1': 'L__self___layer.bias'}, inputs_to_buffers={}, buffers_to_mutate={}, backward_signature=None, assertion_dep_token=None)\n",
      "Symbol to range: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class M(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super(M, self).__init__()\n",
    "        self.layer = nn.Linear(d_in, d_out)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "arg = torch.randn(2, 10)\n",
    "model = M(10, 20)\n",
    "\n",
    "exported = export(model, args=(arg,))\n",
    "print(exported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1897e0e-e42f-4d38-a6d5-456e50f31fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arg0_1\n",
      "arg1_1\n",
      "arg2_1\n",
      "permute\n",
      "addmm\n",
      "output\n"
     ]
    }
   ],
   "source": [
    "for n in exported.graph.nodes:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9c1f5d3-2264-436c-9cbf-c2d66640be78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arg0_1 []\n",
      "arg1_1 []\n",
      "arg2_1 []\n",
      "permute [arg0_1]\n",
      "addmm [arg1_1, arg2_1, permute]\n",
      "output [addmm]\n"
     ]
    }
   ],
   "source": [
    "for n in exported.graph.nodes:\n",
    "    print(n, n.all_input_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "377b2008-a1cd-4b06-a221-5c2ecd00f141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arg0_1 []\n",
      "arg1_1 []\n",
      "arg2_1 []\n",
      "permute [arg0_1]\n",
      "fake tensor arg0_1 FakeTensor(..., size=(20, 10))\n",
      "addmm [arg1_1, arg2_1, permute]\n",
      "fake tensor arg1_1 FakeTensor(..., size=(20,))\n",
      "fake tensor arg2_1 FakeTensor(..., size=(2, 10))\n",
      "fake tensor permute FakeTensor(..., size=(10, 20))\n",
      "output [addmm]\n",
      "fake tensor addmm FakeTensor(..., size=(2, 20))\n"
     ]
    }
   ],
   "source": [
    "for n in exported.graph.nodes:\n",
    "    print(n, n.all_input_nodes)\n",
    "    for a in n.all_input_nodes:\n",
    "        print('fake tensor', a, a.meta['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "286e711d-c7de-4f5a-91e8-7b9e1279f30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addmm\n",
      "addmm flops 800\n"
     ]
    }
   ],
   "source": [
    "def count_addmm_flops(node):\n",
    "    # ignore bias\n",
    "    t1 = node.all_input_nodes[1].meta['val']\n",
    "    t2 = node.all_input_nodes[2].meta['val']\n",
    "    m, k = t1.size()\n",
    "    n = t2.size(1)\n",
    "    return 2 * m * k * n\n",
    "\n",
    "nodes = list(exported.graph.nodes)\n",
    "addmm_node = nodes[-2]\n",
    "print(addmm_node)\n",
    "\n",
    "print('addmm flops', count_addmm_flops(addmm_node))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c63a85b-9b48-4897-954b-1e958d7f9659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aten::addmm'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addmm_node.target.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1a118a0-3135-4c9f-973f-0bbcffc31191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total flops 800\n"
     ]
    }
   ],
   "source": [
    "total_flops = 0\n",
    "for n in exported.graph.nodes:\n",
    "    if isinstance(n.target, torch._ops.OpOverload):\n",
    "        if n.target.name() == 'aten::addmm':\n",
    "            total_flops += count_addmm_flops(n)\n",
    "print('total flops', total_flops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc073be-8a6f-4c87-b5dc-2f781a6f7513",
   "metadata": {},
   "source": [
    "Now let's implement the over nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ab570d9-dc6b-4c0d-8446-8f9edb716952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total flops 800\n"
     ]
    }
   ],
   "source": [
    "def count_bmm_flops(node):\n",
    "    t1 = node.all_input_nodes[0].meta['val']\n",
    "    t2 = node.all_input_nodes[1].meta['val']\n",
    "    batch_size, m, k = t1.size()\n",
    "    n = t2.size(2)\n",
    "    return 2 * batch_size * m * k * n\n",
    "\n",
    "def count_mm_flops(node):\n",
    "    t1 = node.all_input_nodes[0].meta['val']\n",
    "    t2 = node.all_input_nodes[1].meta['val']\n",
    "    m, k = t1.size()\n",
    "    n = t2.size(1)\n",
    "    return 2 * m * k * n\n",
    "\n",
    "total_flops = 0\n",
    "for n in exported.graph.nodes:\n",
    "    if isinstance(n.target, torch._ops.OpOverload):\n",
    "        if n.target.name() == 'aten::addmm':\n",
    "            total_flops += count_addmm_flops(n)\n",
    "        elif n.target.name() == 'aten::mm':\n",
    "            total_flops += count_mm_flops(n)\n",
    "        elif n.target.name() == 'aten::bmm':\n",
    "            total_flops += count_bmm_flops(n)\n",
    "print('total flops', total_flops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566b5d6-f888-4f41-ab71-89f050867f9c",
   "metadata": {},
   "source": [
    "Let's adjust the model so that we have an example for all 3 instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebc67e4c-778b-4570-95c5-ae7f0d89b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class M(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M, self).__init__()\n",
    "        self.layer = nn.Linear(10, 20)\n",
    "        self.param = nn.Parameter(torch.zeros(20, 20))\n",
    "        self.param2 = nn.Parameter(torch.zeros(2, 10, 2))\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = x @ self.param\n",
    "        x = x.view(2, 2, 10)\n",
    "        x = x @ self.param2\n",
    "        return x.view(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f59e71d-3d81-44ea-bfbb-686bee959ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExportedProgram:\n",
      "    class GraphModule(torch.nn.Module):\n",
      "        def forward(self, arg0_1: f32[20, 20], arg1_1: f32[2, 10, 2], arg2_1: f32[20, 10], arg3_1: f32[20], arg4_1: f32[2, 10]):\n",
      "            # \n",
      "            permute: f32[10, 20] = torch.ops.aten.permute.default(arg2_1, [1, 0]);  arg2_1 = None\n",
      "            addmm: f32[2, 20] = torch.ops.aten.addmm.default(arg3_1, arg4_1, permute);  arg3_1 = arg4_1 = permute = None\n",
      "            mm: f32[2, 20] = torch.ops.aten.mm.default(addmm, arg0_1);  addmm = arg0_1 = None\n",
      "            view: f32[2, 2, 10] = torch.ops.aten.view.default(mm, [2, 2, 10]);  mm = None\n",
      "            expand: f32[2, 2, 10] = torch.ops.aten.expand.default(view, [2, 2, 10]);  view = None\n",
      "            view_1: f32[2, 2, 10] = torch.ops.aten.view.default(expand, [2, 2, 10]);  expand = None\n",
      "            expand_1: f32[2, 10, 2] = torch.ops.aten.expand.default(arg1_1, [2, 10, 2]);  arg1_1 = None\n",
      "            view_2: f32[2, 10, 2] = torch.ops.aten.view.default(expand_1, [2, 10, 2]);  expand_1 = None\n",
      "            bmm: f32[2, 2, 2] = torch.ops.aten.bmm.default(view_1, view_2);  view_1 = view_2 = None\n",
      "            view_3: f32[2, 2, 2] = torch.ops.aten.view.default(bmm, [2, 2, 2]);  bmm = None\n",
      "            view_4: f32[2, 4] = torch.ops.aten.view.default(view_3, [2, -1]);  view_3 = None\n",
      "            return (view_4,)\n",
      "            \n",
      "Graph Signature: ExportGraphSignature(parameters=['L__self___param', 'L__self___param2', 'L__self___layer.weight', 'L__self___layer.bias'], buffers=[], user_inputs=['arg4_1'], user_outputs=['view_4'], inputs_to_parameters={'arg0_1': 'L__self___param', 'arg1_1': 'L__self___param2', 'arg2_1': 'L__self___layer.weight', 'arg3_1': 'L__self___layer.bias'}, inputs_to_buffers={}, buffers_to_mutate={}, backward_signature=None, assertion_dep_token=None)\n",
      "Symbol to range: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arg = torch.randn(2, 10)\n",
    "model = M()\n",
    "\n",
    "exported = export(model, args=(arg,))\n",
    "print(exported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75a9cfb0-fb4f-4091-b8a3-edde13c5897f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total flops 2560\n"
     ]
    }
   ],
   "source": [
    "total_flops = 0\n",
    "for n in exported.graph.nodes:\n",
    "    if isinstance(n.target, torch._ops.OpOverload):\n",
    "        if n.target.name() == 'aten::addmm':\n",
    "            total_flops += count_addmm_flops(n)\n",
    "        elif n.target.name() == 'aten::mm':\n",
    "            total_flops += count_mm_flops(n)\n",
    "        elif n.target.name() == 'aten::bmm':\n",
    "            total_flops += count_bmm_flops(n)\n",
    "print('total flops', total_flops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90187c4f-da20-4d4e-a567-8078cd003ff2",
   "metadata": {},
   "source": [
    "Let's make a function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50dcbe8b-557d-41c9-adab-1cdad98ef650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def flops_report(exported_program):\n",
    "    flops = 0\n",
    "    flops_by_type = defaultdict(int)  # Store FLOPs for each type of operation\n",
    "\n",
    "    print('Counting FLOPs for the exported graph...')\n",
    "    \n",
    "    op_to_count_func = {\n",
    "        \"aten::bmm\":count_bmm_flops,\n",
    "        \"aten::addmm\":count_addmm_flops,\n",
    "        \"aten::mm\":count_mm_flops,\n",
    "    }\n",
    "\n",
    "    print(f\"Number of nodes in the exported graph: {len(exported_program.graph.nodes)}\")\n",
    "    print(f\"Tracking operations {list(op_to_count_func.keys())}\")\n",
    "\n",
    "    all_ops = set()\n",
    "\n",
    "    for n in exported_program.graph.nodes:\n",
    "        if isinstance(n.target, torch._ops.OpOverload):\n",
    "            op_type = n.target.name()\n",
    "            all_ops.add(op_type)\n",
    "            flops_for_node = 0\n",
    "\n",
    "            if op_type in op_to_count_func:\n",
    "                flops_for_node = op_to_count_func[op_type](n)\n",
    "                flops_by_type[op_type] += flops_for_node\n",
    "                flops += flops_for_node\n",
    "\n",
    "    print(f\"All operations seen: {list(all_ops)}\")\n",
    "    \n",
    "    print(\"\\nFLOPs by Operation Type:\")\n",
    "    for op_type, flops_for_type in flops_by_type.items():\n",
    "        percentage = (flops_for_type / flops) * 100 if flops != 0 else 0\n",
    "        print(f\"{op_type}: {flops_for_type} FLOPs ({percentage:.4f}%)\")\n",
    "    print(f\"\\nTotal FLOPs: {flops}\")\n",
    "    \n",
    "    return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a9f008a4-8df6-4dd5-96f9-3f4455172c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting FLOPs for the exported graph...\n",
      "Number of nodes in the exported graph: 17\n",
      "Tracking operations ['aten::bmm', 'aten::addmm', 'aten::mm']\n",
      "All operations seen: ['aten::bmm', 'aten::addmm', 'aten::view', 'aten::permute', 'aten::expand', 'aten::mm']\n",
      "\n",
      "FLOPs by Operation Type:\n",
      "aten::addmm: 800 FLOPs (31.2500%)\n",
      "aten::mm: 1600 FLOPs (62.5000%)\n",
      "aten::bmm: 160 FLOPs (6.2500%)\n",
      "\n",
      "Total FLOPs: 2560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops_report(exported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "37781ecd-ca99-4fa5-a382-0b7648ba5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full definition of a GPT Language Model, all of it in this single file.\n",
    "References:\n",
    "1) the official GPT-2 TensorFlow implementation released by OpenAI:\n",
    "https://github.com/openai/gpt-2/blob/master/src/model.py\n",
    "2) huggingface/transformers PyTorch implementation:\n",
    "https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import inspect\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\" LayerNorm but with an optional bias. PyTorch doesn't support simply bias=False \"\"\"\n",
    "\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
    "        # self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "        self.flash = False\n",
    "        if not self.flash:\n",
    "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
    "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                        .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        if self.flash:\n",
    "            # efficient attention using Flash Attention CUDA kernels\n",
    "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
    "        else:\n",
    "            # manual implementation of attention\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 768\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.vocab_size is not None\n",
    "        assert config.block_size is not None\n",
    "        self.config = config\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.dropout),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        # with weight tying when using torch.compile() some warnings get generated:\n",
    "        # \"UserWarning: functional_call was passed multiple values for tied weights.\n",
    "        # This behavior is deprecated and will be an error in future versions\"\n",
    "        # not 100% sure what this is, so far seems to be harmless. TODO investigate\n",
    "        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n",
    "\n",
    "        # init all weights\n",
    "        self.apply(self._init_weights)\n",
    "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        # report number of parameters\n",
    "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
    "\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "        For non-embedding count (default), the position embeddings get subtracted.\n",
    "        The token embeddings would too, except due to the parameter sharing these\n",
    "        params are actually used as weights in the final layer, so we include them.\n",
    "        \"\"\"\n",
    "        n_params = sum(p.numel() for p in self.parameters())\n",
    "        if non_embedding:\n",
    "            n_params -= self.transformer.wpe.weight.numel()\n",
    "        return n_params\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
    "\n",
    "        # forward the GPT model itself\n",
    "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
    "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            # if we are given some desired targets also calculate the loss\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "        else:\n",
    "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
    "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
    "            loss = None\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5864f153-34cd-4e97-a4d4-f99fdaac500d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTConfig(block_size=1024, vocab_size=50304, n_layer=12, n_head=12, n_embd=768, dropout=0.0, bias=True)\n"
     ]
    }
   ],
   "source": [
    "config = GPTConfig()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ca5d2f5-48cb-467d-b0bc-203fd65504c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "number of parameters: 123.69M\n",
      "GPT(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(50304, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (ln_1): LayerNorm()\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm()\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gpt = GPT(config)\n",
    "print(gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e6116b-758a-44c1-b984-d3c01842cfbd",
   "metadata": {},
   "source": [
    "We made two adjustments:\n",
    "\n",
    "1. `self.flash` is always False. Otherwise it will use the flash attention instruction `aten::_scaled_dot_product_flash_attention` which we are not currently tracking.\n",
    "2. `forward(..)` only returns logits and not loss. `export` doesn't like multiple outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c52ab086-6f27-48b0-bd05-a1397375dee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 0, 0, 0]])\n",
      "torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "gpt_input = torch.zeros((1, config.block_size), dtype=torch.long)\n",
    "print(gpt_input)\n",
    "print(gpt_input.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dcac60bb-819b-43fe-862b-09d35446ed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExportedProgram:\n",
      "    class GraphModule(torch.nn.Module):\n",
      "        def forward(self, arg0_1: f32[768], arg1_1: f32[768], arg2_1: f32[768], arg3_1: f32[768], arg4_1: f32[768], arg5_1: f32[768], arg6_1: f32[768], arg7_1: f32[768], arg8_1: f32[768], arg9_1: f32[768], arg10_1: f32[768], arg11_1: f32[768], arg12_1: f32[768], arg13_1: f32[768], arg14_1: f32[768], arg15_1: f32[768], arg16_1: f32[768], arg17_1: f32[768], arg18_1: f32[768], arg19_1: f32[768], arg20_1: f32[768], arg21_1: f32[768], arg22_1: f32[768], arg23_1: f32[768], arg24_1: f32[768], arg25_1: f32[768], arg26_1: f32[768], arg27_1: f32[768], arg28_1: f32[768], arg29_1: f32[768], arg30_1: f32[768], arg31_1: f32[768], arg32_1: f32[768], arg33_1: f32[768], arg34_1: f32[768], arg35_1: f32[768], arg36_1: f32[768], arg37_1: f32[768], arg38_1: f32[768], arg39_1: f32[768], arg40_1: f32[768], arg41_1: f32[768], arg42_1: f32[768], arg43_1: f32[768], arg44_1: f32[768], arg45_1: f32[768], arg46_1: f32[768], arg47_1: f32[768], arg48_1: f32[768], arg49_1: f32[768], arg50_1: f32[50304, 768], arg51_1: f32[1024, 768], arg52_1: f32[2304, 768], arg53_1: f32[2304], arg54_1: f32[768, 768], arg55_1: f32[768], arg56_1: f32[3072, 768], arg57_1: f32[3072], arg58_1: f32[768, 3072], arg59_1: f32[768], arg60_1: f32[2304, 768], arg61_1: f32[2304], arg62_1: f32[768, 768], arg63_1: f32[768], arg64_1: f32[3072, 768], arg65_1: f32[3072], arg66_1: f32[768, 3072], arg67_1: f32[768], arg68_1: f32[2304, 768], arg69_1: f32[2304], arg70_1: f32[768, 768], arg71_1: f32[768], arg72_1: f32[3072, 768], arg73_1: f32[3072], arg74_1: f32[768, 3072], arg75_1: f32[768], arg76_1: f32[2304, 768], arg77_1: f32[2304], arg78_1: f32[768, 768], arg79_1: f32[768], arg80_1: f32[3072, 768], arg81_1: f32[3072], arg82_1: f32[768, 3072], arg83_1: f32[768], arg84_1: f32[2304, 768], arg85_1: f32[2304], arg86_1: f32[768, 768], arg87_1: f32[768], arg88_1: f32[3072, 768], arg89_1: f32[3072], arg90_1: f32[768, 3072], arg91_1: f32[768], arg92_1: f32[2304, 768], arg93_1: f32[2304], arg94_1: f32[768, 768], arg95_1: f32[768], arg96_1: f32[3072, 768], arg97_1: f32[3072], arg98_1: f32[768, 3072], arg99_1: f32[768], arg100_1: f32[2304, 768], arg101_1: f32[2304], arg102_1: f32[768, 768], arg103_1: f32[768], arg104_1: f32[3072, 768], arg105_1: f32[3072], arg106_1: f32[768, 3072], arg107_1: f32[768], arg108_1: f32[2304, 768], arg109_1: f32[2304], arg110_1: f32[768, 768], arg111_1: f32[768], arg112_1: f32[3072, 768], arg113_1: f32[3072], arg114_1: f32[768, 3072], arg115_1: f32[768], arg116_1: f32[2304, 768], arg117_1: f32[2304], arg118_1: f32[768, 768], arg119_1: f32[768], arg120_1: f32[3072, 768], arg121_1: f32[3072], arg122_1: f32[768, 3072], arg123_1: f32[768], arg124_1: f32[2304, 768], arg125_1: f32[2304], arg126_1: f32[768, 768], arg127_1: f32[768], arg128_1: f32[3072, 768], arg129_1: f32[3072], arg130_1: f32[768, 3072], arg131_1: f32[768], arg132_1: f32[2304, 768], arg133_1: f32[2304], arg134_1: f32[768, 768], arg135_1: f32[768], arg136_1: f32[3072, 768], arg137_1: f32[3072], arg138_1: f32[768, 3072], arg139_1: f32[768], arg140_1: f32[2304, 768], arg141_1: f32[2304], arg142_1: f32[768, 768], arg143_1: f32[768], arg144_1: f32[3072, 768], arg145_1: f32[3072], arg146_1: f32[768, 3072], arg147_1: f32[768], arg148_1: f32[50304, 768], arg149_1: f32[1, 1, 1024, 1024], arg150_1: f32[1, 1, 1024, 1024], arg151_1: f32[1, 1, 1024, 1024], arg152_1: f32[1, 1, 1024, 1024], arg153_1: f32[1, 1, 1024, 1024], arg154_1: f32[1, 1, 1024, 1024], arg155_1: f32[1, 1, 1024, 1024], arg156_1: f32[1, 1, 1024, 1024], arg157_1: f32[1, 1, 1024, 1024], arg158_1: f32[1, 1, 1024, 1024], arg159_1: f32[1, 1, 1024, 1024], arg160_1: f32[1, 1, 1024, 1024], arg161_1: i64[1, 1024]):\n",
      "            # \n",
      "            arange: i64[1024] = torch.ops.aten.arange.start_step(0, 1024, dtype = torch.int64, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n",
      "            embedding: f32[1, 1024, 768] = torch.ops.aten.embedding.default(arg50_1, arg161_1);  arg50_1 = arg161_1 = None\n",
      "            embedding_1: f32[1024, 768] = torch.ops.aten.embedding.default(arg51_1, arange);  arg51_1 = arange = None\n",
      "            add: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n",
      "            clone: f32[1, 1024, 768] = torch.ops.aten.clone.default(add);  add = None\n",
      "            native_layer_norm = torch.ops.aten.native_layer_norm.default(clone, [768], arg0_1, arg1_1, 1e-05);  arg0_1 = arg1_1 = None\n",
      "            getitem: f32[1, 1024, 768] = native_layer_norm[0];  native_layer_norm = None\n",
      "            view: f32[1024, 768] = torch.ops.aten.view.default(getitem, [1024, 768]);  getitem = None\n",
      "            permute: f32[768, 2304] = torch.ops.aten.permute.default(arg52_1, [1, 0]);  arg52_1 = None\n",
      "            addmm: f32[1024, 2304] = torch.ops.aten.addmm.default(arg53_1, view, permute);  arg53_1 = view = permute = None\n",
      "            view_1: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm, [1, 1024, 2304]);  addmm = None\n",
      "            split = torch.ops.aten.split.Tensor(view_1, 768, 2);  view_1 = None\n",
      "            getitem_1: f32[1, 1024, 768] = split[0]\n",
      "            getitem_2: f32[1, 1024, 768] = split[1]\n",
      "            getitem_3: f32[1, 1024, 768] = split[2];  split = None\n",
      "            view_2: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_2, [1, 1024, 12, 64]);  getitem_2 = None\n",
      "            permute_1: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_2, [0, 2, 1, 3]);  view_2 = None\n",
      "            view_3: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_1, [1, 1024, 12, 64]);  getitem_1 = None\n",
      "            permute_2: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_3, [0, 2, 1, 3]);  view_3 = None\n",
      "            view_4: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_3, [1, 1024, 12, 64]);  getitem_3 = None\n",
      "            permute_3: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_4, [0, 2, 1, 3]);  view_4 = None\n",
      "            permute_4: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_1, [0, 1, 3, 2]);  permute_1 = None\n",
      "            expand: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_2, [1, 12, 1024, 64]);  permute_2 = None\n",
      "            view_5: f32[12, 1024, 64] = torch.ops.aten.view.default(expand, [12, 1024, 64]);  expand = None\n",
      "            expand_1: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_4, [1, 12, 64, 1024]);  permute_4 = None\n",
      "            view_6: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_1, [12, 64, 1024]);  expand_1 = None\n",
      "            bmm: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_5, view_6);  view_5 = view_6 = None\n",
      "            view_7: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm, [1, 12, 1024, 1024]);  bmm = None\n",
      "            mul: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_7, 0.125);  view_7 = None\n",
      "            slice_1: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg149_1, 0, 0, 9223372036854775807);  arg149_1 = None\n",
      "            slice_2: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_1, 1, 0, 9223372036854775807);  slice_1 = None\n",
      "            eq: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_2, 0);  slice_2 = None\n",
      "            scalar_tensor: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq, scalar_tensor, mul);  eq = scalar_tensor = mul = None\n",
      "            _softmax: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where, -1, False);  where = None\n",
      "            clone_1: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax);  _softmax = None\n",
      "            expand_2: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_1, [1, 12, 1024, 1024]);  clone_1 = None\n",
      "            view_8: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_2, [12, 1024, 1024]);  expand_2 = None\n",
      "            expand_3: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_3, [1, 12, 1024, 64]);  permute_3 = None\n",
      "            view_9: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_3, [12, 1024, 64]);  expand_3 = None\n",
      "            bmm_1: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_8, view_9);  view_8 = view_9 = None\n",
      "            view_10: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_1, [1, 12, 1024, 64]);  bmm_1 = None\n",
      "            permute_5: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_10, [0, 2, 1, 3]);  view_10 = None\n",
      "            clone_2: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_5, memory_format = torch.contiguous_format);  permute_5 = None\n",
      "            view_11: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_2, [1, 1024, 768]);  clone_2 = None\n",
      "            view_12: f32[1024, 768] = torch.ops.aten.view.default(view_11, [1024, 768]);  view_11 = None\n",
      "            permute_6: f32[768, 768] = torch.ops.aten.permute.default(arg54_1, [1, 0]);  arg54_1 = None\n",
      "            addmm_1: f32[1024, 768] = torch.ops.aten.addmm.default(arg55_1, view_12, permute_6);  arg55_1 = view_12 = permute_6 = None\n",
      "            view_13: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_1, [1, 1024, 768]);  addmm_1 = None\n",
      "            clone_3: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_13);  view_13 = None\n",
      "            add_1: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(clone, clone_3);  clone = clone_3 = None\n",
      "            native_layer_norm_1 = torch.ops.aten.native_layer_norm.default(add_1, [768], arg2_1, arg3_1, 1e-05);  arg2_1 = arg3_1 = None\n",
      "            getitem_4: f32[1, 1024, 768] = native_layer_norm_1[0];  native_layer_norm_1 = None\n",
      "            view_14: f32[1024, 768] = torch.ops.aten.view.default(getitem_4, [1024, 768]);  getitem_4 = None\n",
      "            permute_7: f32[768, 3072] = torch.ops.aten.permute.default(arg56_1, [1, 0]);  arg56_1 = None\n",
      "            addmm_2: f32[1024, 3072] = torch.ops.aten.addmm.default(arg57_1, view_14, permute_7);  arg57_1 = view_14 = permute_7 = None\n",
      "            view_15: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_2, [1, 1024, 3072]);  addmm_2 = None\n",
      "            gelu: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_15);  view_15 = None\n",
      "            view_16: f32[1024, 3072] = torch.ops.aten.view.default(gelu, [1024, 3072]);  gelu = None\n",
      "            permute_8: f32[3072, 768] = torch.ops.aten.permute.default(arg58_1, [1, 0]);  arg58_1 = None\n",
      "            addmm_3: f32[1024, 768] = torch.ops.aten.addmm.default(arg59_1, view_16, permute_8);  arg59_1 = view_16 = permute_8 = None\n",
      "            view_17: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_3, [1, 1024, 768]);  addmm_3 = None\n",
      "            clone_4: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_17);  view_17 = None\n",
      "            add_2: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_1, clone_4);  add_1 = clone_4 = None\n",
      "            native_layer_norm_2 = torch.ops.aten.native_layer_norm.default(add_2, [768], arg4_1, arg5_1, 1e-05);  arg4_1 = arg5_1 = None\n",
      "            getitem_5: f32[1, 1024, 768] = native_layer_norm_2[0];  native_layer_norm_2 = None\n",
      "            view_18: f32[1024, 768] = torch.ops.aten.view.default(getitem_5, [1024, 768]);  getitem_5 = None\n",
      "            permute_9: f32[768, 2304] = torch.ops.aten.permute.default(arg60_1, [1, 0]);  arg60_1 = None\n",
      "            addmm_4: f32[1024, 2304] = torch.ops.aten.addmm.default(arg61_1, view_18, permute_9);  arg61_1 = view_18 = permute_9 = None\n",
      "            view_19: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_4, [1, 1024, 2304]);  addmm_4 = None\n",
      "            split_1 = torch.ops.aten.split.Tensor(view_19, 768, 2);  view_19 = None\n",
      "            getitem_6: f32[1, 1024, 768] = split_1[0]\n",
      "            getitem_7: f32[1, 1024, 768] = split_1[1]\n",
      "            getitem_8: f32[1, 1024, 768] = split_1[2];  split_1 = None\n",
      "            view_20: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_7, [1, 1024, 12, 64]);  getitem_7 = None\n",
      "            permute_10: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_20, [0, 2, 1, 3]);  view_20 = None\n",
      "            view_21: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_6, [1, 1024, 12, 64]);  getitem_6 = None\n",
      "            permute_11: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_21, [0, 2, 1, 3]);  view_21 = None\n",
      "            view_22: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_8, [1, 1024, 12, 64]);  getitem_8 = None\n",
      "            permute_12: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_22, [0, 2, 1, 3]);  view_22 = None\n",
      "            permute_13: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_10, [0, 1, 3, 2]);  permute_10 = None\n",
      "            expand_4: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_11, [1, 12, 1024, 64]);  permute_11 = None\n",
      "            view_23: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_4, [12, 1024, 64]);  expand_4 = None\n",
      "            expand_5: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_13, [1, 12, 64, 1024]);  permute_13 = None\n",
      "            view_24: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_5, [12, 64, 1024]);  expand_5 = None\n",
      "            bmm_2: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_23, view_24);  view_23 = view_24 = None\n",
      "            view_25: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_2, [1, 12, 1024, 1024]);  bmm_2 = None\n",
      "            mul_1: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_25, 0.125);  view_25 = None\n",
      "            slice_3: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg150_1, 0, 0, 9223372036854775807);  arg150_1 = None\n",
      "            slice_4: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_3, 1, 0, 9223372036854775807);  slice_3 = None\n",
      "            eq_1: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_4, 0);  slice_4 = None\n",
      "            scalar_tensor_1: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_1: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_1, scalar_tensor_1, mul_1);  eq_1 = scalar_tensor_1 = mul_1 = None\n",
      "            _softmax_1: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_1, -1, False);  where_1 = None\n",
      "            clone_5: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_1);  _softmax_1 = None\n",
      "            expand_6: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_5, [1, 12, 1024, 1024]);  clone_5 = None\n",
      "            view_26: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_6, [12, 1024, 1024]);  expand_6 = None\n",
      "            expand_7: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_12, [1, 12, 1024, 64]);  permute_12 = None\n",
      "            view_27: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_7, [12, 1024, 64]);  expand_7 = None\n",
      "            bmm_3: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_26, view_27);  view_26 = view_27 = None\n",
      "            view_28: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_3, [1, 12, 1024, 64]);  bmm_3 = None\n",
      "            permute_14: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_28, [0, 2, 1, 3]);  view_28 = None\n",
      "            clone_6: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_14, memory_format = torch.contiguous_format);  permute_14 = None\n",
      "            view_29: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_6, [1, 1024, 768]);  clone_6 = None\n",
      "            view_30: f32[1024, 768] = torch.ops.aten.view.default(view_29, [1024, 768]);  view_29 = None\n",
      "            permute_15: f32[768, 768] = torch.ops.aten.permute.default(arg62_1, [1, 0]);  arg62_1 = None\n",
      "            addmm_5: f32[1024, 768] = torch.ops.aten.addmm.default(arg63_1, view_30, permute_15);  arg63_1 = view_30 = permute_15 = None\n",
      "            view_31: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_5, [1, 1024, 768]);  addmm_5 = None\n",
      "            clone_7: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_31);  view_31 = None\n",
      "            add_3: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_2, clone_7);  add_2 = clone_7 = None\n",
      "            native_layer_norm_3 = torch.ops.aten.native_layer_norm.default(add_3, [768], arg6_1, arg7_1, 1e-05);  arg6_1 = arg7_1 = None\n",
      "            getitem_9: f32[1, 1024, 768] = native_layer_norm_3[0];  native_layer_norm_3 = None\n",
      "            view_32: f32[1024, 768] = torch.ops.aten.view.default(getitem_9, [1024, 768]);  getitem_9 = None\n",
      "            permute_16: f32[768, 3072] = torch.ops.aten.permute.default(arg64_1, [1, 0]);  arg64_1 = None\n",
      "            addmm_6: f32[1024, 3072] = torch.ops.aten.addmm.default(arg65_1, view_32, permute_16);  arg65_1 = view_32 = permute_16 = None\n",
      "            view_33: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_6, [1, 1024, 3072]);  addmm_6 = None\n",
      "            gelu_1: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_33);  view_33 = None\n",
      "            view_34: f32[1024, 3072] = torch.ops.aten.view.default(gelu_1, [1024, 3072]);  gelu_1 = None\n",
      "            permute_17: f32[3072, 768] = torch.ops.aten.permute.default(arg66_1, [1, 0]);  arg66_1 = None\n",
      "            addmm_7: f32[1024, 768] = torch.ops.aten.addmm.default(arg67_1, view_34, permute_17);  arg67_1 = view_34 = permute_17 = None\n",
      "            view_35: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_7, [1, 1024, 768]);  addmm_7 = None\n",
      "            clone_8: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_35);  view_35 = None\n",
      "            add_4: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_3, clone_8);  add_3 = clone_8 = None\n",
      "            native_layer_norm_4 = torch.ops.aten.native_layer_norm.default(add_4, [768], arg8_1, arg9_1, 1e-05);  arg8_1 = arg9_1 = None\n",
      "            getitem_10: f32[1, 1024, 768] = native_layer_norm_4[0];  native_layer_norm_4 = None\n",
      "            view_36: f32[1024, 768] = torch.ops.aten.view.default(getitem_10, [1024, 768]);  getitem_10 = None\n",
      "            permute_18: f32[768, 2304] = torch.ops.aten.permute.default(arg68_1, [1, 0]);  arg68_1 = None\n",
      "            addmm_8: f32[1024, 2304] = torch.ops.aten.addmm.default(arg69_1, view_36, permute_18);  arg69_1 = view_36 = permute_18 = None\n",
      "            view_37: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_8, [1, 1024, 2304]);  addmm_8 = None\n",
      "            split_2 = torch.ops.aten.split.Tensor(view_37, 768, 2);  view_37 = None\n",
      "            getitem_11: f32[1, 1024, 768] = split_2[0]\n",
      "            getitem_12: f32[1, 1024, 768] = split_2[1]\n",
      "            getitem_13: f32[1, 1024, 768] = split_2[2];  split_2 = None\n",
      "            view_38: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_12, [1, 1024, 12, 64]);  getitem_12 = None\n",
      "            permute_19: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_38, [0, 2, 1, 3]);  view_38 = None\n",
      "            view_39: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_11, [1, 1024, 12, 64]);  getitem_11 = None\n",
      "            permute_20: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_39, [0, 2, 1, 3]);  view_39 = None\n",
      "            view_40: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_13, [1, 1024, 12, 64]);  getitem_13 = None\n",
      "            permute_21: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_40, [0, 2, 1, 3]);  view_40 = None\n",
      "            permute_22: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_19, [0, 1, 3, 2]);  permute_19 = None\n",
      "            expand_8: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_20, [1, 12, 1024, 64]);  permute_20 = None\n",
      "            view_41: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_8, [12, 1024, 64]);  expand_8 = None\n",
      "            expand_9: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_22, [1, 12, 64, 1024]);  permute_22 = None\n",
      "            view_42: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_9, [12, 64, 1024]);  expand_9 = None\n",
      "            bmm_4: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_41, view_42);  view_41 = view_42 = None\n",
      "            view_43: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_4, [1, 12, 1024, 1024]);  bmm_4 = None\n",
      "            mul_2: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_43, 0.125);  view_43 = None\n",
      "            slice_5: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg151_1, 0, 0, 9223372036854775807);  arg151_1 = None\n",
      "            slice_6: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_5, 1, 0, 9223372036854775807);  slice_5 = None\n",
      "            eq_2: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_6, 0);  slice_6 = None\n",
      "            scalar_tensor_2: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_2: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_2, scalar_tensor_2, mul_2);  eq_2 = scalar_tensor_2 = mul_2 = None\n",
      "            _softmax_2: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_2, -1, False);  where_2 = None\n",
      "            clone_9: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_2);  _softmax_2 = None\n",
      "            expand_10: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_9, [1, 12, 1024, 1024]);  clone_9 = None\n",
      "            view_44: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_10, [12, 1024, 1024]);  expand_10 = None\n",
      "            expand_11: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_21, [1, 12, 1024, 64]);  permute_21 = None\n",
      "            view_45: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_11, [12, 1024, 64]);  expand_11 = None\n",
      "            bmm_5: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_44, view_45);  view_44 = view_45 = None\n",
      "            view_46: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_5, [1, 12, 1024, 64]);  bmm_5 = None\n",
      "            permute_23: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_46, [0, 2, 1, 3]);  view_46 = None\n",
      "            clone_10: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_23, memory_format = torch.contiguous_format);  permute_23 = None\n",
      "            view_47: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_10, [1, 1024, 768]);  clone_10 = None\n",
      "            view_48: f32[1024, 768] = torch.ops.aten.view.default(view_47, [1024, 768]);  view_47 = None\n",
      "            permute_24: f32[768, 768] = torch.ops.aten.permute.default(arg70_1, [1, 0]);  arg70_1 = None\n",
      "            addmm_9: f32[1024, 768] = torch.ops.aten.addmm.default(arg71_1, view_48, permute_24);  arg71_1 = view_48 = permute_24 = None\n",
      "            view_49: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_9, [1, 1024, 768]);  addmm_9 = None\n",
      "            clone_11: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_49);  view_49 = None\n",
      "            add_5: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_4, clone_11);  add_4 = clone_11 = None\n",
      "            native_layer_norm_5 = torch.ops.aten.native_layer_norm.default(add_5, [768], arg10_1, arg11_1, 1e-05);  arg10_1 = arg11_1 = None\n",
      "            getitem_14: f32[1, 1024, 768] = native_layer_norm_5[0];  native_layer_norm_5 = None\n",
      "            view_50: f32[1024, 768] = torch.ops.aten.view.default(getitem_14, [1024, 768]);  getitem_14 = None\n",
      "            permute_25: f32[768, 3072] = torch.ops.aten.permute.default(arg72_1, [1, 0]);  arg72_1 = None\n",
      "            addmm_10: f32[1024, 3072] = torch.ops.aten.addmm.default(arg73_1, view_50, permute_25);  arg73_1 = view_50 = permute_25 = None\n",
      "            view_51: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_10, [1, 1024, 3072]);  addmm_10 = None\n",
      "            gelu_2: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_51);  view_51 = None\n",
      "            view_52: f32[1024, 3072] = torch.ops.aten.view.default(gelu_2, [1024, 3072]);  gelu_2 = None\n",
      "            permute_26: f32[3072, 768] = torch.ops.aten.permute.default(arg74_1, [1, 0]);  arg74_1 = None\n",
      "            addmm_11: f32[1024, 768] = torch.ops.aten.addmm.default(arg75_1, view_52, permute_26);  arg75_1 = view_52 = permute_26 = None\n",
      "            view_53: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_11, [1, 1024, 768]);  addmm_11 = None\n",
      "            clone_12: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_53);  view_53 = None\n",
      "            add_6: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_5, clone_12);  add_5 = clone_12 = None\n",
      "            native_layer_norm_6 = torch.ops.aten.native_layer_norm.default(add_6, [768], arg12_1, arg13_1, 1e-05);  arg12_1 = arg13_1 = None\n",
      "            getitem_15: f32[1, 1024, 768] = native_layer_norm_6[0];  native_layer_norm_6 = None\n",
      "            view_54: f32[1024, 768] = torch.ops.aten.view.default(getitem_15, [1024, 768]);  getitem_15 = None\n",
      "            permute_27: f32[768, 2304] = torch.ops.aten.permute.default(arg76_1, [1, 0]);  arg76_1 = None\n",
      "            addmm_12: f32[1024, 2304] = torch.ops.aten.addmm.default(arg77_1, view_54, permute_27);  arg77_1 = view_54 = permute_27 = None\n",
      "            view_55: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_12, [1, 1024, 2304]);  addmm_12 = None\n",
      "            split_3 = torch.ops.aten.split.Tensor(view_55, 768, 2);  view_55 = None\n",
      "            getitem_16: f32[1, 1024, 768] = split_3[0]\n",
      "            getitem_17: f32[1, 1024, 768] = split_3[1]\n",
      "            getitem_18: f32[1, 1024, 768] = split_3[2];  split_3 = None\n",
      "            view_56: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_17, [1, 1024, 12, 64]);  getitem_17 = None\n",
      "            permute_28: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_56, [0, 2, 1, 3]);  view_56 = None\n",
      "            view_57: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_16, [1, 1024, 12, 64]);  getitem_16 = None\n",
      "            permute_29: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_57, [0, 2, 1, 3]);  view_57 = None\n",
      "            view_58: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_18, [1, 1024, 12, 64]);  getitem_18 = None\n",
      "            permute_30: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_58, [0, 2, 1, 3]);  view_58 = None\n",
      "            permute_31: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_28, [0, 1, 3, 2]);  permute_28 = None\n",
      "            expand_12: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_29, [1, 12, 1024, 64]);  permute_29 = None\n",
      "            view_59: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_12, [12, 1024, 64]);  expand_12 = None\n",
      "            expand_13: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_31, [1, 12, 64, 1024]);  permute_31 = None\n",
      "            view_60: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_13, [12, 64, 1024]);  expand_13 = None\n",
      "            bmm_6: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_59, view_60);  view_59 = view_60 = None\n",
      "            view_61: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_6, [1, 12, 1024, 1024]);  bmm_6 = None\n",
      "            mul_3: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_61, 0.125);  view_61 = None\n",
      "            slice_7: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg152_1, 0, 0, 9223372036854775807);  arg152_1 = None\n",
      "            slice_8: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_7, 1, 0, 9223372036854775807);  slice_7 = None\n",
      "            eq_3: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_8, 0);  slice_8 = None\n",
      "            scalar_tensor_3: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_3: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_3, scalar_tensor_3, mul_3);  eq_3 = scalar_tensor_3 = mul_3 = None\n",
      "            _softmax_3: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_3, -1, False);  where_3 = None\n",
      "            clone_13: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_3);  _softmax_3 = None\n",
      "            expand_14: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_13, [1, 12, 1024, 1024]);  clone_13 = None\n",
      "            view_62: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_14, [12, 1024, 1024]);  expand_14 = None\n",
      "            expand_15: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_30, [1, 12, 1024, 64]);  permute_30 = None\n",
      "            view_63: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_15, [12, 1024, 64]);  expand_15 = None\n",
      "            bmm_7: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_62, view_63);  view_62 = view_63 = None\n",
      "            view_64: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_7, [1, 12, 1024, 64]);  bmm_7 = None\n",
      "            permute_32: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_64, [0, 2, 1, 3]);  view_64 = None\n",
      "            clone_14: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_32, memory_format = torch.contiguous_format);  permute_32 = None\n",
      "            view_65: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_14, [1, 1024, 768]);  clone_14 = None\n",
      "            view_66: f32[1024, 768] = torch.ops.aten.view.default(view_65, [1024, 768]);  view_65 = None\n",
      "            permute_33: f32[768, 768] = torch.ops.aten.permute.default(arg78_1, [1, 0]);  arg78_1 = None\n",
      "            addmm_13: f32[1024, 768] = torch.ops.aten.addmm.default(arg79_1, view_66, permute_33);  arg79_1 = view_66 = permute_33 = None\n",
      "            view_67: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_13, [1, 1024, 768]);  addmm_13 = None\n",
      "            clone_15: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_67);  view_67 = None\n",
      "            add_7: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_6, clone_15);  add_6 = clone_15 = None\n",
      "            native_layer_norm_7 = torch.ops.aten.native_layer_norm.default(add_7, [768], arg14_1, arg15_1, 1e-05);  arg14_1 = arg15_1 = None\n",
      "            getitem_19: f32[1, 1024, 768] = native_layer_norm_7[0];  native_layer_norm_7 = None\n",
      "            view_68: f32[1024, 768] = torch.ops.aten.view.default(getitem_19, [1024, 768]);  getitem_19 = None\n",
      "            permute_34: f32[768, 3072] = torch.ops.aten.permute.default(arg80_1, [1, 0]);  arg80_1 = None\n",
      "            addmm_14: f32[1024, 3072] = torch.ops.aten.addmm.default(arg81_1, view_68, permute_34);  arg81_1 = view_68 = permute_34 = None\n",
      "            view_69: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_14, [1, 1024, 3072]);  addmm_14 = None\n",
      "            gelu_3: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_69);  view_69 = None\n",
      "            view_70: f32[1024, 3072] = torch.ops.aten.view.default(gelu_3, [1024, 3072]);  gelu_3 = None\n",
      "            permute_35: f32[3072, 768] = torch.ops.aten.permute.default(arg82_1, [1, 0]);  arg82_1 = None\n",
      "            addmm_15: f32[1024, 768] = torch.ops.aten.addmm.default(arg83_1, view_70, permute_35);  arg83_1 = view_70 = permute_35 = None\n",
      "            view_71: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_15, [1, 1024, 768]);  addmm_15 = None\n",
      "            clone_16: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_71);  view_71 = None\n",
      "            add_8: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_7, clone_16);  add_7 = clone_16 = None\n",
      "            native_layer_norm_8 = torch.ops.aten.native_layer_norm.default(add_8, [768], arg16_1, arg17_1, 1e-05);  arg16_1 = arg17_1 = None\n",
      "            getitem_20: f32[1, 1024, 768] = native_layer_norm_8[0];  native_layer_norm_8 = None\n",
      "            view_72: f32[1024, 768] = torch.ops.aten.view.default(getitem_20, [1024, 768]);  getitem_20 = None\n",
      "            permute_36: f32[768, 2304] = torch.ops.aten.permute.default(arg84_1, [1, 0]);  arg84_1 = None\n",
      "            addmm_16: f32[1024, 2304] = torch.ops.aten.addmm.default(arg85_1, view_72, permute_36);  arg85_1 = view_72 = permute_36 = None\n",
      "            view_73: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_16, [1, 1024, 2304]);  addmm_16 = None\n",
      "            split_4 = torch.ops.aten.split.Tensor(view_73, 768, 2);  view_73 = None\n",
      "            getitem_21: f32[1, 1024, 768] = split_4[0]\n",
      "            getitem_22: f32[1, 1024, 768] = split_4[1]\n",
      "            getitem_23: f32[1, 1024, 768] = split_4[2];  split_4 = None\n",
      "            view_74: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_22, [1, 1024, 12, 64]);  getitem_22 = None\n",
      "            permute_37: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_74, [0, 2, 1, 3]);  view_74 = None\n",
      "            view_75: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_21, [1, 1024, 12, 64]);  getitem_21 = None\n",
      "            permute_38: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_75, [0, 2, 1, 3]);  view_75 = None\n",
      "            view_76: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_23, [1, 1024, 12, 64]);  getitem_23 = None\n",
      "            permute_39: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_76, [0, 2, 1, 3]);  view_76 = None\n",
      "            permute_40: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_37, [0, 1, 3, 2]);  permute_37 = None\n",
      "            expand_16: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_38, [1, 12, 1024, 64]);  permute_38 = None\n",
      "            view_77: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_16, [12, 1024, 64]);  expand_16 = None\n",
      "            expand_17: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_40, [1, 12, 64, 1024]);  permute_40 = None\n",
      "            view_78: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_17, [12, 64, 1024]);  expand_17 = None\n",
      "            bmm_8: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_77, view_78);  view_77 = view_78 = None\n",
      "            view_79: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_8, [1, 12, 1024, 1024]);  bmm_8 = None\n",
      "            mul_4: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_79, 0.125);  view_79 = None\n",
      "            slice_9: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg153_1, 0, 0, 9223372036854775807);  arg153_1 = None\n",
      "            slice_10: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_9, 1, 0, 9223372036854775807);  slice_9 = None\n",
      "            eq_4: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_10, 0);  slice_10 = None\n",
      "            scalar_tensor_4: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_4: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_4, scalar_tensor_4, mul_4);  eq_4 = scalar_tensor_4 = mul_4 = None\n",
      "            _softmax_4: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_4, -1, False);  where_4 = None\n",
      "            clone_17: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_4);  _softmax_4 = None\n",
      "            expand_18: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_17, [1, 12, 1024, 1024]);  clone_17 = None\n",
      "            view_80: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_18, [12, 1024, 1024]);  expand_18 = None\n",
      "            expand_19: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_39, [1, 12, 1024, 64]);  permute_39 = None\n",
      "            view_81: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_19, [12, 1024, 64]);  expand_19 = None\n",
      "            bmm_9: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_80, view_81);  view_80 = view_81 = None\n",
      "            view_82: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_9, [1, 12, 1024, 64]);  bmm_9 = None\n",
      "            permute_41: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_82, [0, 2, 1, 3]);  view_82 = None\n",
      "            clone_18: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_41, memory_format = torch.contiguous_format);  permute_41 = None\n",
      "            view_83: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_18, [1, 1024, 768]);  clone_18 = None\n",
      "            view_84: f32[1024, 768] = torch.ops.aten.view.default(view_83, [1024, 768]);  view_83 = None\n",
      "            permute_42: f32[768, 768] = torch.ops.aten.permute.default(arg86_1, [1, 0]);  arg86_1 = None\n",
      "            addmm_17: f32[1024, 768] = torch.ops.aten.addmm.default(arg87_1, view_84, permute_42);  arg87_1 = view_84 = permute_42 = None\n",
      "            view_85: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_17, [1, 1024, 768]);  addmm_17 = None\n",
      "            clone_19: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_85);  view_85 = None\n",
      "            add_9: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_8, clone_19);  add_8 = clone_19 = None\n",
      "            native_layer_norm_9 = torch.ops.aten.native_layer_norm.default(add_9, [768], arg18_1, arg19_1, 1e-05);  arg18_1 = arg19_1 = None\n",
      "            getitem_24: f32[1, 1024, 768] = native_layer_norm_9[0];  native_layer_norm_9 = None\n",
      "            view_86: f32[1024, 768] = torch.ops.aten.view.default(getitem_24, [1024, 768]);  getitem_24 = None\n",
      "            permute_43: f32[768, 3072] = torch.ops.aten.permute.default(arg88_1, [1, 0]);  arg88_1 = None\n",
      "            addmm_18: f32[1024, 3072] = torch.ops.aten.addmm.default(arg89_1, view_86, permute_43);  arg89_1 = view_86 = permute_43 = None\n",
      "            view_87: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_18, [1, 1024, 3072]);  addmm_18 = None\n",
      "            gelu_4: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_87);  view_87 = None\n",
      "            view_88: f32[1024, 3072] = torch.ops.aten.view.default(gelu_4, [1024, 3072]);  gelu_4 = None\n",
      "            permute_44: f32[3072, 768] = torch.ops.aten.permute.default(arg90_1, [1, 0]);  arg90_1 = None\n",
      "            addmm_19: f32[1024, 768] = torch.ops.aten.addmm.default(arg91_1, view_88, permute_44);  arg91_1 = view_88 = permute_44 = None\n",
      "            view_89: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_19, [1, 1024, 768]);  addmm_19 = None\n",
      "            clone_20: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_89);  view_89 = None\n",
      "            add_10: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_9, clone_20);  add_9 = clone_20 = None\n",
      "            native_layer_norm_10 = torch.ops.aten.native_layer_norm.default(add_10, [768], arg20_1, arg21_1, 1e-05);  arg20_1 = arg21_1 = None\n",
      "            getitem_25: f32[1, 1024, 768] = native_layer_norm_10[0];  native_layer_norm_10 = None\n",
      "            view_90: f32[1024, 768] = torch.ops.aten.view.default(getitem_25, [1024, 768]);  getitem_25 = None\n",
      "            permute_45: f32[768, 2304] = torch.ops.aten.permute.default(arg92_1, [1, 0]);  arg92_1 = None\n",
      "            addmm_20: f32[1024, 2304] = torch.ops.aten.addmm.default(arg93_1, view_90, permute_45);  arg93_1 = view_90 = permute_45 = None\n",
      "            view_91: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_20, [1, 1024, 2304]);  addmm_20 = None\n",
      "            split_5 = torch.ops.aten.split.Tensor(view_91, 768, 2);  view_91 = None\n",
      "            getitem_26: f32[1, 1024, 768] = split_5[0]\n",
      "            getitem_27: f32[1, 1024, 768] = split_5[1]\n",
      "            getitem_28: f32[1, 1024, 768] = split_5[2];  split_5 = None\n",
      "            view_92: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_27, [1, 1024, 12, 64]);  getitem_27 = None\n",
      "            permute_46: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_92, [0, 2, 1, 3]);  view_92 = None\n",
      "            view_93: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_26, [1, 1024, 12, 64]);  getitem_26 = None\n",
      "            permute_47: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_93, [0, 2, 1, 3]);  view_93 = None\n",
      "            view_94: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_28, [1, 1024, 12, 64]);  getitem_28 = None\n",
      "            permute_48: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_94, [0, 2, 1, 3]);  view_94 = None\n",
      "            permute_49: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_46, [0, 1, 3, 2]);  permute_46 = None\n",
      "            expand_20: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_47, [1, 12, 1024, 64]);  permute_47 = None\n",
      "            view_95: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_20, [12, 1024, 64]);  expand_20 = None\n",
      "            expand_21: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_49, [1, 12, 64, 1024]);  permute_49 = None\n",
      "            view_96: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_21, [12, 64, 1024]);  expand_21 = None\n",
      "            bmm_10: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_95, view_96);  view_95 = view_96 = None\n",
      "            view_97: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_10, [1, 12, 1024, 1024]);  bmm_10 = None\n",
      "            mul_5: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_97, 0.125);  view_97 = None\n",
      "            slice_11: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg154_1, 0, 0, 9223372036854775807);  arg154_1 = None\n",
      "            slice_12: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_11, 1, 0, 9223372036854775807);  slice_11 = None\n",
      "            eq_5: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_12, 0);  slice_12 = None\n",
      "            scalar_tensor_5: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_5: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_5, scalar_tensor_5, mul_5);  eq_5 = scalar_tensor_5 = mul_5 = None\n",
      "            _softmax_5: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_5, -1, False);  where_5 = None\n",
      "            clone_21: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_5);  _softmax_5 = None\n",
      "            expand_22: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_21, [1, 12, 1024, 1024]);  clone_21 = None\n",
      "            view_98: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_22, [12, 1024, 1024]);  expand_22 = None\n",
      "            expand_23: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_48, [1, 12, 1024, 64]);  permute_48 = None\n",
      "            view_99: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_23, [12, 1024, 64]);  expand_23 = None\n",
      "            bmm_11: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_98, view_99);  view_98 = view_99 = None\n",
      "            view_100: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_11, [1, 12, 1024, 64]);  bmm_11 = None\n",
      "            permute_50: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_100, [0, 2, 1, 3]);  view_100 = None\n",
      "            clone_22: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_50, memory_format = torch.contiguous_format);  permute_50 = None\n",
      "            view_101: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_22, [1, 1024, 768]);  clone_22 = None\n",
      "            view_102: f32[1024, 768] = torch.ops.aten.view.default(view_101, [1024, 768]);  view_101 = None\n",
      "            permute_51: f32[768, 768] = torch.ops.aten.permute.default(arg94_1, [1, 0]);  arg94_1 = None\n",
      "            addmm_21: f32[1024, 768] = torch.ops.aten.addmm.default(arg95_1, view_102, permute_51);  arg95_1 = view_102 = permute_51 = None\n",
      "            view_103: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_21, [1, 1024, 768]);  addmm_21 = None\n",
      "            clone_23: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_103);  view_103 = None\n",
      "            add_11: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_10, clone_23);  add_10 = clone_23 = None\n",
      "            native_layer_norm_11 = torch.ops.aten.native_layer_norm.default(add_11, [768], arg22_1, arg23_1, 1e-05);  arg22_1 = arg23_1 = None\n",
      "            getitem_29: f32[1, 1024, 768] = native_layer_norm_11[0];  native_layer_norm_11 = None\n",
      "            view_104: f32[1024, 768] = torch.ops.aten.view.default(getitem_29, [1024, 768]);  getitem_29 = None\n",
      "            permute_52: f32[768, 3072] = torch.ops.aten.permute.default(arg96_1, [1, 0]);  arg96_1 = None\n",
      "            addmm_22: f32[1024, 3072] = torch.ops.aten.addmm.default(arg97_1, view_104, permute_52);  arg97_1 = view_104 = permute_52 = None\n",
      "            view_105: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_22, [1, 1024, 3072]);  addmm_22 = None\n",
      "            gelu_5: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_105);  view_105 = None\n",
      "            view_106: f32[1024, 3072] = torch.ops.aten.view.default(gelu_5, [1024, 3072]);  gelu_5 = None\n",
      "            permute_53: f32[3072, 768] = torch.ops.aten.permute.default(arg98_1, [1, 0]);  arg98_1 = None\n",
      "            addmm_23: f32[1024, 768] = torch.ops.aten.addmm.default(arg99_1, view_106, permute_53);  arg99_1 = view_106 = permute_53 = None\n",
      "            view_107: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_23, [1, 1024, 768]);  addmm_23 = None\n",
      "            clone_24: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_107);  view_107 = None\n",
      "            add_12: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_11, clone_24);  add_11 = clone_24 = None\n",
      "            native_layer_norm_12 = torch.ops.aten.native_layer_norm.default(add_12, [768], arg24_1, arg25_1, 1e-05);  arg24_1 = arg25_1 = None\n",
      "            getitem_30: f32[1, 1024, 768] = native_layer_norm_12[0];  native_layer_norm_12 = None\n",
      "            view_108: f32[1024, 768] = torch.ops.aten.view.default(getitem_30, [1024, 768]);  getitem_30 = None\n",
      "            permute_54: f32[768, 2304] = torch.ops.aten.permute.default(arg100_1, [1, 0]);  arg100_1 = None\n",
      "            addmm_24: f32[1024, 2304] = torch.ops.aten.addmm.default(arg101_1, view_108, permute_54);  arg101_1 = view_108 = permute_54 = None\n",
      "            view_109: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_24, [1, 1024, 2304]);  addmm_24 = None\n",
      "            split_6 = torch.ops.aten.split.Tensor(view_109, 768, 2);  view_109 = None\n",
      "            getitem_31: f32[1, 1024, 768] = split_6[0]\n",
      "            getitem_32: f32[1, 1024, 768] = split_6[1]\n",
      "            getitem_33: f32[1, 1024, 768] = split_6[2];  split_6 = None\n",
      "            view_110: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_32, [1, 1024, 12, 64]);  getitem_32 = None\n",
      "            permute_55: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_110, [0, 2, 1, 3]);  view_110 = None\n",
      "            view_111: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_31, [1, 1024, 12, 64]);  getitem_31 = None\n",
      "            permute_56: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_111, [0, 2, 1, 3]);  view_111 = None\n",
      "            view_112: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_33, [1, 1024, 12, 64]);  getitem_33 = None\n",
      "            permute_57: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_112, [0, 2, 1, 3]);  view_112 = None\n",
      "            permute_58: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_55, [0, 1, 3, 2]);  permute_55 = None\n",
      "            expand_24: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_56, [1, 12, 1024, 64]);  permute_56 = None\n",
      "            view_113: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_24, [12, 1024, 64]);  expand_24 = None\n",
      "            expand_25: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_58, [1, 12, 64, 1024]);  permute_58 = None\n",
      "            view_114: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_25, [12, 64, 1024]);  expand_25 = None\n",
      "            bmm_12: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_113, view_114);  view_113 = view_114 = None\n",
      "            view_115: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_12, [1, 12, 1024, 1024]);  bmm_12 = None\n",
      "            mul_6: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_115, 0.125);  view_115 = None\n",
      "            slice_13: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg155_1, 0, 0, 9223372036854775807);  arg155_1 = None\n",
      "            slice_14: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_13, 1, 0, 9223372036854775807);  slice_13 = None\n",
      "            eq_6: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_14, 0);  slice_14 = None\n",
      "            scalar_tensor_6: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_6: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_6, scalar_tensor_6, mul_6);  eq_6 = scalar_tensor_6 = mul_6 = None\n",
      "            _softmax_6: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_6, -1, False);  where_6 = None\n",
      "            clone_25: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_6);  _softmax_6 = None\n",
      "            expand_26: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_25, [1, 12, 1024, 1024]);  clone_25 = None\n",
      "            view_116: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_26, [12, 1024, 1024]);  expand_26 = None\n",
      "            expand_27: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_57, [1, 12, 1024, 64]);  permute_57 = None\n",
      "            view_117: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_27, [12, 1024, 64]);  expand_27 = None\n",
      "            bmm_13: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_116, view_117);  view_116 = view_117 = None\n",
      "            view_118: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_13, [1, 12, 1024, 64]);  bmm_13 = None\n",
      "            permute_59: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_118, [0, 2, 1, 3]);  view_118 = None\n",
      "            clone_26: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_59, memory_format = torch.contiguous_format);  permute_59 = None\n",
      "            view_119: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_26, [1, 1024, 768]);  clone_26 = None\n",
      "            view_120: f32[1024, 768] = torch.ops.aten.view.default(view_119, [1024, 768]);  view_119 = None\n",
      "            permute_60: f32[768, 768] = torch.ops.aten.permute.default(arg102_1, [1, 0]);  arg102_1 = None\n",
      "            addmm_25: f32[1024, 768] = torch.ops.aten.addmm.default(arg103_1, view_120, permute_60);  arg103_1 = view_120 = permute_60 = None\n",
      "            view_121: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_25, [1, 1024, 768]);  addmm_25 = None\n",
      "            clone_27: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_121);  view_121 = None\n",
      "            add_13: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_12, clone_27);  add_12 = clone_27 = None\n",
      "            native_layer_norm_13 = torch.ops.aten.native_layer_norm.default(add_13, [768], arg26_1, arg27_1, 1e-05);  arg26_1 = arg27_1 = None\n",
      "            getitem_34: f32[1, 1024, 768] = native_layer_norm_13[0];  native_layer_norm_13 = None\n",
      "            view_122: f32[1024, 768] = torch.ops.aten.view.default(getitem_34, [1024, 768]);  getitem_34 = None\n",
      "            permute_61: f32[768, 3072] = torch.ops.aten.permute.default(arg104_1, [1, 0]);  arg104_1 = None\n",
      "            addmm_26: f32[1024, 3072] = torch.ops.aten.addmm.default(arg105_1, view_122, permute_61);  arg105_1 = view_122 = permute_61 = None\n",
      "            view_123: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_26, [1, 1024, 3072]);  addmm_26 = None\n",
      "            gelu_6: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_123);  view_123 = None\n",
      "            view_124: f32[1024, 3072] = torch.ops.aten.view.default(gelu_6, [1024, 3072]);  gelu_6 = None\n",
      "            permute_62: f32[3072, 768] = torch.ops.aten.permute.default(arg106_1, [1, 0]);  arg106_1 = None\n",
      "            addmm_27: f32[1024, 768] = torch.ops.aten.addmm.default(arg107_1, view_124, permute_62);  arg107_1 = view_124 = permute_62 = None\n",
      "            view_125: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_27, [1, 1024, 768]);  addmm_27 = None\n",
      "            clone_28: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_125);  view_125 = None\n",
      "            add_14: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_13, clone_28);  add_13 = clone_28 = None\n",
      "            native_layer_norm_14 = torch.ops.aten.native_layer_norm.default(add_14, [768], arg28_1, arg29_1, 1e-05);  arg28_1 = arg29_1 = None\n",
      "            getitem_35: f32[1, 1024, 768] = native_layer_norm_14[0];  native_layer_norm_14 = None\n",
      "            view_126: f32[1024, 768] = torch.ops.aten.view.default(getitem_35, [1024, 768]);  getitem_35 = None\n",
      "            permute_63: f32[768, 2304] = torch.ops.aten.permute.default(arg108_1, [1, 0]);  arg108_1 = None\n",
      "            addmm_28: f32[1024, 2304] = torch.ops.aten.addmm.default(arg109_1, view_126, permute_63);  arg109_1 = view_126 = permute_63 = None\n",
      "            view_127: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_28, [1, 1024, 2304]);  addmm_28 = None\n",
      "            split_7 = torch.ops.aten.split.Tensor(view_127, 768, 2);  view_127 = None\n",
      "            getitem_36: f32[1, 1024, 768] = split_7[0]\n",
      "            getitem_37: f32[1, 1024, 768] = split_7[1]\n",
      "            getitem_38: f32[1, 1024, 768] = split_7[2];  split_7 = None\n",
      "            view_128: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_37, [1, 1024, 12, 64]);  getitem_37 = None\n",
      "            permute_64: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_128, [0, 2, 1, 3]);  view_128 = None\n",
      "            view_129: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_36, [1, 1024, 12, 64]);  getitem_36 = None\n",
      "            permute_65: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_129, [0, 2, 1, 3]);  view_129 = None\n",
      "            view_130: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_38, [1, 1024, 12, 64]);  getitem_38 = None\n",
      "            permute_66: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_130, [0, 2, 1, 3]);  view_130 = None\n",
      "            permute_67: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_64, [0, 1, 3, 2]);  permute_64 = None\n",
      "            expand_28: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_65, [1, 12, 1024, 64]);  permute_65 = None\n",
      "            view_131: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_28, [12, 1024, 64]);  expand_28 = None\n",
      "            expand_29: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_67, [1, 12, 64, 1024]);  permute_67 = None\n",
      "            view_132: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_29, [12, 64, 1024]);  expand_29 = None\n",
      "            bmm_14: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_131, view_132);  view_131 = view_132 = None\n",
      "            view_133: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_14, [1, 12, 1024, 1024]);  bmm_14 = None\n",
      "            mul_7: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_133, 0.125);  view_133 = None\n",
      "            slice_15: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg156_1, 0, 0, 9223372036854775807);  arg156_1 = None\n",
      "            slice_16: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_15, 1, 0, 9223372036854775807);  slice_15 = None\n",
      "            eq_7: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_16, 0);  slice_16 = None\n",
      "            scalar_tensor_7: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_7: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_7, scalar_tensor_7, mul_7);  eq_7 = scalar_tensor_7 = mul_7 = None\n",
      "            _softmax_7: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_7, -1, False);  where_7 = None\n",
      "            clone_29: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_7);  _softmax_7 = None\n",
      "            expand_30: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_29, [1, 12, 1024, 1024]);  clone_29 = None\n",
      "            view_134: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_30, [12, 1024, 1024]);  expand_30 = None\n",
      "            expand_31: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_66, [1, 12, 1024, 64]);  permute_66 = None\n",
      "            view_135: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_31, [12, 1024, 64]);  expand_31 = None\n",
      "            bmm_15: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_134, view_135);  view_134 = view_135 = None\n",
      "            view_136: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_15, [1, 12, 1024, 64]);  bmm_15 = None\n",
      "            permute_68: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_136, [0, 2, 1, 3]);  view_136 = None\n",
      "            clone_30: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_68, memory_format = torch.contiguous_format);  permute_68 = None\n",
      "            view_137: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_30, [1, 1024, 768]);  clone_30 = None\n",
      "            view_138: f32[1024, 768] = torch.ops.aten.view.default(view_137, [1024, 768]);  view_137 = None\n",
      "            permute_69: f32[768, 768] = torch.ops.aten.permute.default(arg110_1, [1, 0]);  arg110_1 = None\n",
      "            addmm_29: f32[1024, 768] = torch.ops.aten.addmm.default(arg111_1, view_138, permute_69);  arg111_1 = view_138 = permute_69 = None\n",
      "            view_139: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_29, [1, 1024, 768]);  addmm_29 = None\n",
      "            clone_31: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_139);  view_139 = None\n",
      "            add_15: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_14, clone_31);  add_14 = clone_31 = None\n",
      "            native_layer_norm_15 = torch.ops.aten.native_layer_norm.default(add_15, [768], arg30_1, arg31_1, 1e-05);  arg30_1 = arg31_1 = None\n",
      "            getitem_39: f32[1, 1024, 768] = native_layer_norm_15[0];  native_layer_norm_15 = None\n",
      "            view_140: f32[1024, 768] = torch.ops.aten.view.default(getitem_39, [1024, 768]);  getitem_39 = None\n",
      "            permute_70: f32[768, 3072] = torch.ops.aten.permute.default(arg112_1, [1, 0]);  arg112_1 = None\n",
      "            addmm_30: f32[1024, 3072] = torch.ops.aten.addmm.default(arg113_1, view_140, permute_70);  arg113_1 = view_140 = permute_70 = None\n",
      "            view_141: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_30, [1, 1024, 3072]);  addmm_30 = None\n",
      "            gelu_7: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_141);  view_141 = None\n",
      "            view_142: f32[1024, 3072] = torch.ops.aten.view.default(gelu_7, [1024, 3072]);  gelu_7 = None\n",
      "            permute_71: f32[3072, 768] = torch.ops.aten.permute.default(arg114_1, [1, 0]);  arg114_1 = None\n",
      "            addmm_31: f32[1024, 768] = torch.ops.aten.addmm.default(arg115_1, view_142, permute_71);  arg115_1 = view_142 = permute_71 = None\n",
      "            view_143: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_31, [1, 1024, 768]);  addmm_31 = None\n",
      "            clone_32: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_143);  view_143 = None\n",
      "            add_16: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_15, clone_32);  add_15 = clone_32 = None\n",
      "            native_layer_norm_16 = torch.ops.aten.native_layer_norm.default(add_16, [768], arg32_1, arg33_1, 1e-05);  arg32_1 = arg33_1 = None\n",
      "            getitem_40: f32[1, 1024, 768] = native_layer_norm_16[0];  native_layer_norm_16 = None\n",
      "            view_144: f32[1024, 768] = torch.ops.aten.view.default(getitem_40, [1024, 768]);  getitem_40 = None\n",
      "            permute_72: f32[768, 2304] = torch.ops.aten.permute.default(arg116_1, [1, 0]);  arg116_1 = None\n",
      "            addmm_32: f32[1024, 2304] = torch.ops.aten.addmm.default(arg117_1, view_144, permute_72);  arg117_1 = view_144 = permute_72 = None\n",
      "            view_145: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_32, [1, 1024, 2304]);  addmm_32 = None\n",
      "            split_8 = torch.ops.aten.split.Tensor(view_145, 768, 2);  view_145 = None\n",
      "            getitem_41: f32[1, 1024, 768] = split_8[0]\n",
      "            getitem_42: f32[1, 1024, 768] = split_8[1]\n",
      "            getitem_43: f32[1, 1024, 768] = split_8[2];  split_8 = None\n",
      "            view_146: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_42, [1, 1024, 12, 64]);  getitem_42 = None\n",
      "            permute_73: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_146, [0, 2, 1, 3]);  view_146 = None\n",
      "            view_147: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_41, [1, 1024, 12, 64]);  getitem_41 = None\n",
      "            permute_74: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_147, [0, 2, 1, 3]);  view_147 = None\n",
      "            view_148: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_43, [1, 1024, 12, 64]);  getitem_43 = None\n",
      "            permute_75: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_148, [0, 2, 1, 3]);  view_148 = None\n",
      "            permute_76: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_73, [0, 1, 3, 2]);  permute_73 = None\n",
      "            expand_32: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_74, [1, 12, 1024, 64]);  permute_74 = None\n",
      "            view_149: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_32, [12, 1024, 64]);  expand_32 = None\n",
      "            expand_33: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_76, [1, 12, 64, 1024]);  permute_76 = None\n",
      "            view_150: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_33, [12, 64, 1024]);  expand_33 = None\n",
      "            bmm_16: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_149, view_150);  view_149 = view_150 = None\n",
      "            view_151: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_16, [1, 12, 1024, 1024]);  bmm_16 = None\n",
      "            mul_8: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_151, 0.125);  view_151 = None\n",
      "            slice_17: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg157_1, 0, 0, 9223372036854775807);  arg157_1 = None\n",
      "            slice_18: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_17, 1, 0, 9223372036854775807);  slice_17 = None\n",
      "            eq_8: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_18, 0);  slice_18 = None\n",
      "            scalar_tensor_8: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_8: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_8, scalar_tensor_8, mul_8);  eq_8 = scalar_tensor_8 = mul_8 = None\n",
      "            _softmax_8: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_8, -1, False);  where_8 = None\n",
      "            clone_33: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_8);  _softmax_8 = None\n",
      "            expand_34: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_33, [1, 12, 1024, 1024]);  clone_33 = None\n",
      "            view_152: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_34, [12, 1024, 1024]);  expand_34 = None\n",
      "            expand_35: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_75, [1, 12, 1024, 64]);  permute_75 = None\n",
      "            view_153: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_35, [12, 1024, 64]);  expand_35 = None\n",
      "            bmm_17: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_152, view_153);  view_152 = view_153 = None\n",
      "            view_154: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_17, [1, 12, 1024, 64]);  bmm_17 = None\n",
      "            permute_77: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_154, [0, 2, 1, 3]);  view_154 = None\n",
      "            clone_34: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_77, memory_format = torch.contiguous_format);  permute_77 = None\n",
      "            view_155: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_34, [1, 1024, 768]);  clone_34 = None\n",
      "            view_156: f32[1024, 768] = torch.ops.aten.view.default(view_155, [1024, 768]);  view_155 = None\n",
      "            permute_78: f32[768, 768] = torch.ops.aten.permute.default(arg118_1, [1, 0]);  arg118_1 = None\n",
      "            addmm_33: f32[1024, 768] = torch.ops.aten.addmm.default(arg119_1, view_156, permute_78);  arg119_1 = view_156 = permute_78 = None\n",
      "            view_157: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_33, [1, 1024, 768]);  addmm_33 = None\n",
      "            clone_35: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_157);  view_157 = None\n",
      "            add_17: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_16, clone_35);  add_16 = clone_35 = None\n",
      "            native_layer_norm_17 = torch.ops.aten.native_layer_norm.default(add_17, [768], arg34_1, arg35_1, 1e-05);  arg34_1 = arg35_1 = None\n",
      "            getitem_44: f32[1, 1024, 768] = native_layer_norm_17[0];  native_layer_norm_17 = None\n",
      "            view_158: f32[1024, 768] = torch.ops.aten.view.default(getitem_44, [1024, 768]);  getitem_44 = None\n",
      "            permute_79: f32[768, 3072] = torch.ops.aten.permute.default(arg120_1, [1, 0]);  arg120_1 = None\n",
      "            addmm_34: f32[1024, 3072] = torch.ops.aten.addmm.default(arg121_1, view_158, permute_79);  arg121_1 = view_158 = permute_79 = None\n",
      "            view_159: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_34, [1, 1024, 3072]);  addmm_34 = None\n",
      "            gelu_8: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_159);  view_159 = None\n",
      "            view_160: f32[1024, 3072] = torch.ops.aten.view.default(gelu_8, [1024, 3072]);  gelu_8 = None\n",
      "            permute_80: f32[3072, 768] = torch.ops.aten.permute.default(arg122_1, [1, 0]);  arg122_1 = None\n",
      "            addmm_35: f32[1024, 768] = torch.ops.aten.addmm.default(arg123_1, view_160, permute_80);  arg123_1 = view_160 = permute_80 = None\n",
      "            view_161: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_35, [1, 1024, 768]);  addmm_35 = None\n",
      "            clone_36: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_161);  view_161 = None\n",
      "            add_18: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_17, clone_36);  add_17 = clone_36 = None\n",
      "            native_layer_norm_18 = torch.ops.aten.native_layer_norm.default(add_18, [768], arg36_1, arg37_1, 1e-05);  arg36_1 = arg37_1 = None\n",
      "            getitem_45: f32[1, 1024, 768] = native_layer_norm_18[0];  native_layer_norm_18 = None\n",
      "            view_162: f32[1024, 768] = torch.ops.aten.view.default(getitem_45, [1024, 768]);  getitem_45 = None\n",
      "            permute_81: f32[768, 2304] = torch.ops.aten.permute.default(arg124_1, [1, 0]);  arg124_1 = None\n",
      "            addmm_36: f32[1024, 2304] = torch.ops.aten.addmm.default(arg125_1, view_162, permute_81);  arg125_1 = view_162 = permute_81 = None\n",
      "            view_163: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_36, [1, 1024, 2304]);  addmm_36 = None\n",
      "            split_9 = torch.ops.aten.split.Tensor(view_163, 768, 2);  view_163 = None\n",
      "            getitem_46: f32[1, 1024, 768] = split_9[0]\n",
      "            getitem_47: f32[1, 1024, 768] = split_9[1]\n",
      "            getitem_48: f32[1, 1024, 768] = split_9[2];  split_9 = None\n",
      "            view_164: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_47, [1, 1024, 12, 64]);  getitem_47 = None\n",
      "            permute_82: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_164, [0, 2, 1, 3]);  view_164 = None\n",
      "            view_165: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_46, [1, 1024, 12, 64]);  getitem_46 = None\n",
      "            permute_83: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_165, [0, 2, 1, 3]);  view_165 = None\n",
      "            view_166: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_48, [1, 1024, 12, 64]);  getitem_48 = None\n",
      "            permute_84: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_166, [0, 2, 1, 3]);  view_166 = None\n",
      "            permute_85: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_82, [0, 1, 3, 2]);  permute_82 = None\n",
      "            expand_36: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_83, [1, 12, 1024, 64]);  permute_83 = None\n",
      "            view_167: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_36, [12, 1024, 64]);  expand_36 = None\n",
      "            expand_37: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_85, [1, 12, 64, 1024]);  permute_85 = None\n",
      "            view_168: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_37, [12, 64, 1024]);  expand_37 = None\n",
      "            bmm_18: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_167, view_168);  view_167 = view_168 = None\n",
      "            view_169: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_18, [1, 12, 1024, 1024]);  bmm_18 = None\n",
      "            mul_9: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_169, 0.125);  view_169 = None\n",
      "            slice_19: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg158_1, 0, 0, 9223372036854775807);  arg158_1 = None\n",
      "            slice_20: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_19, 1, 0, 9223372036854775807);  slice_19 = None\n",
      "            eq_9: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_20, 0);  slice_20 = None\n",
      "            scalar_tensor_9: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_9: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_9, scalar_tensor_9, mul_9);  eq_9 = scalar_tensor_9 = mul_9 = None\n",
      "            _softmax_9: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_9, -1, False);  where_9 = None\n",
      "            clone_37: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_9);  _softmax_9 = None\n",
      "            expand_38: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_37, [1, 12, 1024, 1024]);  clone_37 = None\n",
      "            view_170: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_38, [12, 1024, 1024]);  expand_38 = None\n",
      "            expand_39: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_84, [1, 12, 1024, 64]);  permute_84 = None\n",
      "            view_171: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_39, [12, 1024, 64]);  expand_39 = None\n",
      "            bmm_19: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_170, view_171);  view_170 = view_171 = None\n",
      "            view_172: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_19, [1, 12, 1024, 64]);  bmm_19 = None\n",
      "            permute_86: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_172, [0, 2, 1, 3]);  view_172 = None\n",
      "            clone_38: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_86, memory_format = torch.contiguous_format);  permute_86 = None\n",
      "            view_173: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_38, [1, 1024, 768]);  clone_38 = None\n",
      "            view_174: f32[1024, 768] = torch.ops.aten.view.default(view_173, [1024, 768]);  view_173 = None\n",
      "            permute_87: f32[768, 768] = torch.ops.aten.permute.default(arg126_1, [1, 0]);  arg126_1 = None\n",
      "            addmm_37: f32[1024, 768] = torch.ops.aten.addmm.default(arg127_1, view_174, permute_87);  arg127_1 = view_174 = permute_87 = None\n",
      "            view_175: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_37, [1, 1024, 768]);  addmm_37 = None\n",
      "            clone_39: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_175);  view_175 = None\n",
      "            add_19: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_18, clone_39);  add_18 = clone_39 = None\n",
      "            native_layer_norm_19 = torch.ops.aten.native_layer_norm.default(add_19, [768], arg38_1, arg39_1, 1e-05);  arg38_1 = arg39_1 = None\n",
      "            getitem_49: f32[1, 1024, 768] = native_layer_norm_19[0];  native_layer_norm_19 = None\n",
      "            view_176: f32[1024, 768] = torch.ops.aten.view.default(getitem_49, [1024, 768]);  getitem_49 = None\n",
      "            permute_88: f32[768, 3072] = torch.ops.aten.permute.default(arg128_1, [1, 0]);  arg128_1 = None\n",
      "            addmm_38: f32[1024, 3072] = torch.ops.aten.addmm.default(arg129_1, view_176, permute_88);  arg129_1 = view_176 = permute_88 = None\n",
      "            view_177: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_38, [1, 1024, 3072]);  addmm_38 = None\n",
      "            gelu_9: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_177);  view_177 = None\n",
      "            view_178: f32[1024, 3072] = torch.ops.aten.view.default(gelu_9, [1024, 3072]);  gelu_9 = None\n",
      "            permute_89: f32[3072, 768] = torch.ops.aten.permute.default(arg130_1, [1, 0]);  arg130_1 = None\n",
      "            addmm_39: f32[1024, 768] = torch.ops.aten.addmm.default(arg131_1, view_178, permute_89);  arg131_1 = view_178 = permute_89 = None\n",
      "            view_179: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_39, [1, 1024, 768]);  addmm_39 = None\n",
      "            clone_40: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_179);  view_179 = None\n",
      "            add_20: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_19, clone_40);  add_19 = clone_40 = None\n",
      "            native_layer_norm_20 = torch.ops.aten.native_layer_norm.default(add_20, [768], arg40_1, arg41_1, 1e-05);  arg40_1 = arg41_1 = None\n",
      "            getitem_50: f32[1, 1024, 768] = native_layer_norm_20[0];  native_layer_norm_20 = None\n",
      "            view_180: f32[1024, 768] = torch.ops.aten.view.default(getitem_50, [1024, 768]);  getitem_50 = None\n",
      "            permute_90: f32[768, 2304] = torch.ops.aten.permute.default(arg132_1, [1, 0]);  arg132_1 = None\n",
      "            addmm_40: f32[1024, 2304] = torch.ops.aten.addmm.default(arg133_1, view_180, permute_90);  arg133_1 = view_180 = permute_90 = None\n",
      "            view_181: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_40, [1, 1024, 2304]);  addmm_40 = None\n",
      "            split_10 = torch.ops.aten.split.Tensor(view_181, 768, 2);  view_181 = None\n",
      "            getitem_51: f32[1, 1024, 768] = split_10[0]\n",
      "            getitem_52: f32[1, 1024, 768] = split_10[1]\n",
      "            getitem_53: f32[1, 1024, 768] = split_10[2];  split_10 = None\n",
      "            view_182: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_52, [1, 1024, 12, 64]);  getitem_52 = None\n",
      "            permute_91: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_182, [0, 2, 1, 3]);  view_182 = None\n",
      "            view_183: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_51, [1, 1024, 12, 64]);  getitem_51 = None\n",
      "            permute_92: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_183, [0, 2, 1, 3]);  view_183 = None\n",
      "            view_184: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_53, [1, 1024, 12, 64]);  getitem_53 = None\n",
      "            permute_93: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_184, [0, 2, 1, 3]);  view_184 = None\n",
      "            permute_94: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_91, [0, 1, 3, 2]);  permute_91 = None\n",
      "            expand_40: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_92, [1, 12, 1024, 64]);  permute_92 = None\n",
      "            view_185: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_40, [12, 1024, 64]);  expand_40 = None\n",
      "            expand_41: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_94, [1, 12, 64, 1024]);  permute_94 = None\n",
      "            view_186: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_41, [12, 64, 1024]);  expand_41 = None\n",
      "            bmm_20: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_185, view_186);  view_185 = view_186 = None\n",
      "            view_187: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_20, [1, 12, 1024, 1024]);  bmm_20 = None\n",
      "            mul_10: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_187, 0.125);  view_187 = None\n",
      "            slice_21: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg159_1, 0, 0, 9223372036854775807);  arg159_1 = None\n",
      "            slice_22: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_21, 1, 0, 9223372036854775807);  slice_21 = None\n",
      "            eq_10: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_22, 0);  slice_22 = None\n",
      "            scalar_tensor_10: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_10: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_10, scalar_tensor_10, mul_10);  eq_10 = scalar_tensor_10 = mul_10 = None\n",
      "            _softmax_10: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_10, -1, False);  where_10 = None\n",
      "            clone_41: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_10);  _softmax_10 = None\n",
      "            expand_42: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_41, [1, 12, 1024, 1024]);  clone_41 = None\n",
      "            view_188: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_42, [12, 1024, 1024]);  expand_42 = None\n",
      "            expand_43: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_93, [1, 12, 1024, 64]);  permute_93 = None\n",
      "            view_189: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_43, [12, 1024, 64]);  expand_43 = None\n",
      "            bmm_21: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_188, view_189);  view_188 = view_189 = None\n",
      "            view_190: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_21, [1, 12, 1024, 64]);  bmm_21 = None\n",
      "            permute_95: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_190, [0, 2, 1, 3]);  view_190 = None\n",
      "            clone_42: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_95, memory_format = torch.contiguous_format);  permute_95 = None\n",
      "            view_191: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_42, [1, 1024, 768]);  clone_42 = None\n",
      "            view_192: f32[1024, 768] = torch.ops.aten.view.default(view_191, [1024, 768]);  view_191 = None\n",
      "            permute_96: f32[768, 768] = torch.ops.aten.permute.default(arg134_1, [1, 0]);  arg134_1 = None\n",
      "            addmm_41: f32[1024, 768] = torch.ops.aten.addmm.default(arg135_1, view_192, permute_96);  arg135_1 = view_192 = permute_96 = None\n",
      "            view_193: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_41, [1, 1024, 768]);  addmm_41 = None\n",
      "            clone_43: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_193);  view_193 = None\n",
      "            add_21: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_20, clone_43);  add_20 = clone_43 = None\n",
      "            native_layer_norm_21 = torch.ops.aten.native_layer_norm.default(add_21, [768], arg42_1, arg43_1, 1e-05);  arg42_1 = arg43_1 = None\n",
      "            getitem_54: f32[1, 1024, 768] = native_layer_norm_21[0];  native_layer_norm_21 = None\n",
      "            view_194: f32[1024, 768] = torch.ops.aten.view.default(getitem_54, [1024, 768]);  getitem_54 = None\n",
      "            permute_97: f32[768, 3072] = torch.ops.aten.permute.default(arg136_1, [1, 0]);  arg136_1 = None\n",
      "            addmm_42: f32[1024, 3072] = torch.ops.aten.addmm.default(arg137_1, view_194, permute_97);  arg137_1 = view_194 = permute_97 = None\n",
      "            view_195: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_42, [1, 1024, 3072]);  addmm_42 = None\n",
      "            gelu_10: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_195);  view_195 = None\n",
      "            view_196: f32[1024, 3072] = torch.ops.aten.view.default(gelu_10, [1024, 3072]);  gelu_10 = None\n",
      "            permute_98: f32[3072, 768] = torch.ops.aten.permute.default(arg138_1, [1, 0]);  arg138_1 = None\n",
      "            addmm_43: f32[1024, 768] = torch.ops.aten.addmm.default(arg139_1, view_196, permute_98);  arg139_1 = view_196 = permute_98 = None\n",
      "            view_197: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_43, [1, 1024, 768]);  addmm_43 = None\n",
      "            clone_44: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_197);  view_197 = None\n",
      "            add_22: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_21, clone_44);  add_21 = clone_44 = None\n",
      "            native_layer_norm_22 = torch.ops.aten.native_layer_norm.default(add_22, [768], arg44_1, arg45_1, 1e-05);  arg44_1 = arg45_1 = None\n",
      "            getitem_55: f32[1, 1024, 768] = native_layer_norm_22[0];  native_layer_norm_22 = None\n",
      "            view_198: f32[1024, 768] = torch.ops.aten.view.default(getitem_55, [1024, 768]);  getitem_55 = None\n",
      "            permute_99: f32[768, 2304] = torch.ops.aten.permute.default(arg140_1, [1, 0]);  arg140_1 = None\n",
      "            addmm_44: f32[1024, 2304] = torch.ops.aten.addmm.default(arg141_1, view_198, permute_99);  arg141_1 = view_198 = permute_99 = None\n",
      "            view_199: f32[1, 1024, 2304] = torch.ops.aten.view.default(addmm_44, [1, 1024, 2304]);  addmm_44 = None\n",
      "            split_11 = torch.ops.aten.split.Tensor(view_199, 768, 2);  view_199 = None\n",
      "            getitem_56: f32[1, 1024, 768] = split_11[0]\n",
      "            getitem_57: f32[1, 1024, 768] = split_11[1]\n",
      "            getitem_58: f32[1, 1024, 768] = split_11[2];  split_11 = None\n",
      "            view_200: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_57, [1, 1024, 12, 64]);  getitem_57 = None\n",
      "            permute_100: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_200, [0, 2, 1, 3]);  view_200 = None\n",
      "            view_201: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_56, [1, 1024, 12, 64]);  getitem_56 = None\n",
      "            permute_101: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_201, [0, 2, 1, 3]);  view_201 = None\n",
      "            view_202: f32[1, 1024, 12, 64] = torch.ops.aten.view.default(getitem_58, [1, 1024, 12, 64]);  getitem_58 = None\n",
      "            permute_102: f32[1, 12, 1024, 64] = torch.ops.aten.permute.default(view_202, [0, 2, 1, 3]);  view_202 = None\n",
      "            permute_103: f32[1, 12, 64, 1024] = torch.ops.aten.permute.default(permute_100, [0, 1, 3, 2]);  permute_100 = None\n",
      "            expand_44: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_101, [1, 12, 1024, 64]);  permute_101 = None\n",
      "            view_203: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_44, [12, 1024, 64]);  expand_44 = None\n",
      "            expand_45: f32[1, 12, 64, 1024] = torch.ops.aten.expand.default(permute_103, [1, 12, 64, 1024]);  permute_103 = None\n",
      "            view_204: f32[12, 64, 1024] = torch.ops.aten.view.default(expand_45, [12, 64, 1024]);  expand_45 = None\n",
      "            bmm_22: f32[12, 1024, 1024] = torch.ops.aten.bmm.default(view_203, view_204);  view_203 = view_204 = None\n",
      "            view_205: f32[1, 12, 1024, 1024] = torch.ops.aten.view.default(bmm_22, [1, 12, 1024, 1024]);  bmm_22 = None\n",
      "            mul_11: f32[1, 12, 1024, 1024] = torch.ops.aten.mul.Tensor(view_205, 0.125);  view_205 = None\n",
      "            slice_23: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(arg160_1, 0, 0, 9223372036854775807);  arg160_1 = None\n",
      "            slice_24: f32[1, 1, 1024, 1024] = torch.ops.aten.slice.Tensor(slice_23, 1, 0, 9223372036854775807);  slice_23 = None\n",
      "            eq_11: b8[1, 1, 1024, 1024] = torch.ops.aten.eq.Scalar(slice_24, 0);  slice_24 = None\n",
      "            scalar_tensor_11: f32[] = torch.ops.aten.scalar_tensor.default(-inf, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "            where_11: f32[1, 12, 1024, 1024] = torch.ops.aten.where.self(eq_11, scalar_tensor_11, mul_11);  eq_11 = scalar_tensor_11 = mul_11 = None\n",
      "            _softmax_11: f32[1, 12, 1024, 1024] = torch.ops.aten._softmax.default(where_11, -1, False);  where_11 = None\n",
      "            clone_45: f32[1, 12, 1024, 1024] = torch.ops.aten.clone.default(_softmax_11);  _softmax_11 = None\n",
      "            expand_46: f32[1, 12, 1024, 1024] = torch.ops.aten.expand.default(clone_45, [1, 12, 1024, 1024]);  clone_45 = None\n",
      "            view_206: f32[12, 1024, 1024] = torch.ops.aten.view.default(expand_46, [12, 1024, 1024]);  expand_46 = None\n",
      "            expand_47: f32[1, 12, 1024, 64] = torch.ops.aten.expand.default(permute_102, [1, 12, 1024, 64]);  permute_102 = None\n",
      "            view_207: f32[12, 1024, 64] = torch.ops.aten.view.default(expand_47, [12, 1024, 64]);  expand_47 = None\n",
      "            bmm_23: f32[12, 1024, 64] = torch.ops.aten.bmm.default(view_206, view_207);  view_206 = view_207 = None\n",
      "            view_208: f32[1, 12, 1024, 64] = torch.ops.aten.view.default(bmm_23, [1, 12, 1024, 64]);  bmm_23 = None\n",
      "            permute_104: f32[1, 1024, 12, 64] = torch.ops.aten.permute.default(view_208, [0, 2, 1, 3]);  view_208 = None\n",
      "            clone_46: f32[1, 1024, 12, 64] = torch.ops.aten.clone.default(permute_104, memory_format = torch.contiguous_format);  permute_104 = None\n",
      "            view_209: f32[1, 1024, 768] = torch.ops.aten.view.default(clone_46, [1, 1024, 768]);  clone_46 = None\n",
      "            view_210: f32[1024, 768] = torch.ops.aten.view.default(view_209, [1024, 768]);  view_209 = None\n",
      "            permute_105: f32[768, 768] = torch.ops.aten.permute.default(arg142_1, [1, 0]);  arg142_1 = None\n",
      "            addmm_45: f32[1024, 768] = torch.ops.aten.addmm.default(arg143_1, view_210, permute_105);  arg143_1 = view_210 = permute_105 = None\n",
      "            view_211: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_45, [1, 1024, 768]);  addmm_45 = None\n",
      "            clone_47: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_211);  view_211 = None\n",
      "            add_23: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_22, clone_47);  add_22 = clone_47 = None\n",
      "            native_layer_norm_23 = torch.ops.aten.native_layer_norm.default(add_23, [768], arg46_1, arg47_1, 1e-05);  arg46_1 = arg47_1 = None\n",
      "            getitem_59: f32[1, 1024, 768] = native_layer_norm_23[0];  native_layer_norm_23 = None\n",
      "            view_212: f32[1024, 768] = torch.ops.aten.view.default(getitem_59, [1024, 768]);  getitem_59 = None\n",
      "            permute_106: f32[768, 3072] = torch.ops.aten.permute.default(arg144_1, [1, 0]);  arg144_1 = None\n",
      "            addmm_46: f32[1024, 3072] = torch.ops.aten.addmm.default(arg145_1, view_212, permute_106);  arg145_1 = view_212 = permute_106 = None\n",
      "            view_213: f32[1, 1024, 3072] = torch.ops.aten.view.default(addmm_46, [1, 1024, 3072]);  addmm_46 = None\n",
      "            gelu_11: f32[1, 1024, 3072] = torch.ops.aten.gelu.default(view_213);  view_213 = None\n",
      "            view_214: f32[1024, 3072] = torch.ops.aten.view.default(gelu_11, [1024, 3072]);  gelu_11 = None\n",
      "            permute_107: f32[3072, 768] = torch.ops.aten.permute.default(arg146_1, [1, 0]);  arg146_1 = None\n",
      "            addmm_47: f32[1024, 768] = torch.ops.aten.addmm.default(arg147_1, view_214, permute_107);  arg147_1 = view_214 = permute_107 = None\n",
      "            view_215: f32[1, 1024, 768] = torch.ops.aten.view.default(addmm_47, [1, 1024, 768]);  addmm_47 = None\n",
      "            clone_48: f32[1, 1024, 768] = torch.ops.aten.clone.default(view_215);  view_215 = None\n",
      "            add_24: f32[1, 1024, 768] = torch.ops.aten.add.Tensor(add_23, clone_48);  add_23 = clone_48 = None\n",
      "            native_layer_norm_24 = torch.ops.aten.native_layer_norm.default(add_24, [768], arg48_1, arg49_1, 1e-05);  add_24 = arg48_1 = arg49_1 = None\n",
      "            getitem_60: f32[1, 1024, 768] = native_layer_norm_24[0];  native_layer_norm_24 = None\n",
      "            slice_25: f32[1, 1024, 768] = torch.ops.aten.slice.Tensor(getitem_60, 0, 0, 9223372036854775807);  getitem_60 = None\n",
      "            _tensor_constant0: i64[1] = self._tensor_constant0\n",
      "            lift_fresh_copy: i64[1] = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None\n",
      "            slice_26: f32[1, 1024, 768] = torch.ops.aten.slice.Tensor(slice_25, 2, 0, 9223372036854775807);  slice_25 = None\n",
      "            index: f32[1, 1, 768] = torch.ops.aten.index.Tensor(slice_26, [None, lift_fresh_copy]);  slice_26 = lift_fresh_copy = None\n",
      "            permute_108: f32[768, 50304] = torch.ops.aten.permute.default(arg148_1, [1, 0]);  arg148_1 = None\n",
      "            view_216: f32[1, 768] = torch.ops.aten.view.default(index, [1, 768]);  index = None\n",
      "            mm: f32[1, 50304] = torch.ops.aten.mm.default(view_216, permute_108);  view_216 = permute_108 = None\n",
      "            view_217: f32[1, 1, 50304] = torch.ops.aten.view.default(mm, [1, 1, 50304]);  mm = None\n",
      "            return (view_217,)\n",
      "            \n",
      "Graph Signature: ExportGraphSignature(parameters=['L__self___transformer_h_0_ln_1_weight', 'L__self___transformer_h_0_ln_1_bias', 'L__self___transformer_h_0_ln_2_weight', 'L__self___transformer_h_0_ln_2_bias', 'L__self___transformer_h_1_ln_1_weight', 'L__self___transformer_h_1_ln_1_bias', 'L__self___transformer_h_1_ln_2_weight', 'L__self___transformer_h_1_ln_2_bias', 'L__self___transformer_h_2_ln_1_weight', 'L__self___transformer_h_2_ln_1_bias', 'L__self___transformer_h_2_ln_2_weight', 'L__self___transformer_h_2_ln_2_bias', 'L__self___transformer_h_3_ln_1_weight', 'L__self___transformer_h_3_ln_1_bias', 'L__self___transformer_h_3_ln_2_weight', 'L__self___transformer_h_3_ln_2_bias', 'L__self___transformer_h_4_ln_1_weight', 'L__self___transformer_h_4_ln_1_bias', 'L__self___transformer_h_4_ln_2_weight', 'L__self___transformer_h_4_ln_2_bias', 'L__self___transformer_h_5_ln_1_weight', 'L__self___transformer_h_5_ln_1_bias', 'L__self___transformer_h_5_ln_2_weight', 'L__self___transformer_h_5_ln_2_bias', 'L__self___transformer_h_6_ln_1_weight', 'L__self___transformer_h_6_ln_1_bias', 'L__self___transformer_h_6_ln_2_weight', 'L__self___transformer_h_6_ln_2_bias', 'L__self___transformer_h_7_ln_1_weight', 'L__self___transformer_h_7_ln_1_bias', 'L__self___transformer_h_7_ln_2_weight', 'L__self___transformer_h_7_ln_2_bias', 'L__self___transformer_h_8_ln_1_weight', 'L__self___transformer_h_8_ln_1_bias', 'L__self___transformer_h_8_ln_2_weight', 'L__self___transformer_h_8_ln_2_bias', 'L__self___transformer_h_9_ln_1_weight', 'L__self___transformer_h_9_ln_1_bias', 'L__self___transformer_h_9_ln_2_weight', 'L__self___transformer_h_9_ln_2_bias', 'L__self___transformer_h_10_ln_1_weight', 'L__self___transformer_h_10_ln_1_bias', 'L__self___transformer_h_10_ln_2_weight', 'L__self___transformer_h_10_ln_2_bias', 'L__self___transformer_h_11_ln_1_weight', 'L__self___transformer_h_11_ln_1_bias', 'L__self___transformer_h_11_ln_2_weight', 'L__self___transformer_h_11_ln_2_bias', 'L__self___transformer_ln_f_weight', 'L__self___transformer_ln_f_bias', 'L__self___transformer_wte.weight', 'L__self___transformer_wpe.weight', 'L__self___transformer_h_0_attn_c_attn.weight', 'L__self___transformer_h_0_attn_c_attn.bias', 'L__self___transformer_h_0_attn_c_proj.weight', 'L__self___transformer_h_0_attn_c_proj.bias', 'L__self___transformer_h_0_mlp_c_fc.weight', 'L__self___transformer_h_0_mlp_c_fc.bias', 'L__self___transformer_h_0_mlp_c_proj.weight', 'L__self___transformer_h_0_mlp_c_proj.bias', 'L__self___transformer_h_1_attn_c_attn.weight', 'L__self___transformer_h_1_attn_c_attn.bias', 'L__self___transformer_h_1_attn_c_proj.weight', 'L__self___transformer_h_1_attn_c_proj.bias', 'L__self___transformer_h_1_mlp_c_fc.weight', 'L__self___transformer_h_1_mlp_c_fc.bias', 'L__self___transformer_h_1_mlp_c_proj.weight', 'L__self___transformer_h_1_mlp_c_proj.bias', 'L__self___transformer_h_2_attn_c_attn.weight', 'L__self___transformer_h_2_attn_c_attn.bias', 'L__self___transformer_h_2_attn_c_proj.weight', 'L__self___transformer_h_2_attn_c_proj.bias', 'L__self___transformer_h_2_mlp_c_fc.weight', 'L__self___transformer_h_2_mlp_c_fc.bias', 'L__self___transformer_h_2_mlp_c_proj.weight', 'L__self___transformer_h_2_mlp_c_proj.bias', 'L__self___transformer_h_3_attn_c_attn.weight', 'L__self___transformer_h_3_attn_c_attn.bias', 'L__self___transformer_h_3_attn_c_proj.weight', 'L__self___transformer_h_3_attn_c_proj.bias', 'L__self___transformer_h_3_mlp_c_fc.weight', 'L__self___transformer_h_3_mlp_c_fc.bias', 'L__self___transformer_h_3_mlp_c_proj.weight', 'L__self___transformer_h_3_mlp_c_proj.bias', 'L__self___transformer_h_4_attn_c_attn.weight', 'L__self___transformer_h_4_attn_c_attn.bias', 'L__self___transformer_h_4_attn_c_proj.weight', 'L__self___transformer_h_4_attn_c_proj.bias', 'L__self___transformer_h_4_mlp_c_fc.weight', 'L__self___transformer_h_4_mlp_c_fc.bias', 'L__self___transformer_h_4_mlp_c_proj.weight', 'L__self___transformer_h_4_mlp_c_proj.bias', 'L__self___transformer_h_5_attn_c_attn.weight', 'L__self___transformer_h_5_attn_c_attn.bias', 'L__self___transformer_h_5_attn_c_proj.weight', 'L__self___transformer_h_5_attn_c_proj.bias', 'L__self___transformer_h_5_mlp_c_fc.weight', 'L__self___transformer_h_5_mlp_c_fc.bias', 'L__self___transformer_h_5_mlp_c_proj.weight', 'L__self___transformer_h_5_mlp_c_proj.bias', 'L__self___transformer_h_6_attn_c_attn.weight', 'L__self___transformer_h_6_attn_c_attn.bias', 'L__self___transformer_h_6_attn_c_proj.weight', 'L__self___transformer_h_6_attn_c_proj.bias', 'L__self___transformer_h_6_mlp_c_fc.weight', 'L__self___transformer_h_6_mlp_c_fc.bias', 'L__self___transformer_h_6_mlp_c_proj.weight', 'L__self___transformer_h_6_mlp_c_proj.bias', 'L__self___transformer_h_7_attn_c_attn.weight', 'L__self___transformer_h_7_attn_c_attn.bias', 'L__self___transformer_h_7_attn_c_proj.weight', 'L__self___transformer_h_7_attn_c_proj.bias', 'L__self___transformer_h_7_mlp_c_fc.weight', 'L__self___transformer_h_7_mlp_c_fc.bias', 'L__self___transformer_h_7_mlp_c_proj.weight', 'L__self___transformer_h_7_mlp_c_proj.bias', 'L__self___transformer_h_8_attn_c_attn.weight', 'L__self___transformer_h_8_attn_c_attn.bias', 'L__self___transformer_h_8_attn_c_proj.weight', 'L__self___transformer_h_8_attn_c_proj.bias', 'L__self___transformer_h_8_mlp_c_fc.weight', 'L__self___transformer_h_8_mlp_c_fc.bias', 'L__self___transformer_h_8_mlp_c_proj.weight', 'L__self___transformer_h_8_mlp_c_proj.bias', 'L__self___transformer_h_9_attn_c_attn.weight', 'L__self___transformer_h_9_attn_c_attn.bias', 'L__self___transformer_h_9_attn_c_proj.weight', 'L__self___transformer_h_9_attn_c_proj.bias', 'L__self___transformer_h_9_mlp_c_fc.weight', 'L__self___transformer_h_9_mlp_c_fc.bias', 'L__self___transformer_h_9_mlp_c_proj.weight', 'L__self___transformer_h_9_mlp_c_proj.bias', 'L__self___transformer_h_10_attn_c_attn.weight', 'L__self___transformer_h_10_attn_c_attn.bias', 'L__self___transformer_h_10_attn_c_proj.weight', 'L__self___transformer_h_10_attn_c_proj.bias', 'L__self___transformer_h_10_mlp_c_fc.weight', 'L__self___transformer_h_10_mlp_c_fc.bias', 'L__self___transformer_h_10_mlp_c_proj.weight', 'L__self___transformer_h_10_mlp_c_proj.bias', 'L__self___transformer_h_11_attn_c_attn.weight', 'L__self___transformer_h_11_attn_c_attn.bias', 'L__self___transformer_h_11_attn_c_proj.weight', 'L__self___transformer_h_11_attn_c_proj.bias', 'L__self___transformer_h_11_mlp_c_fc.weight', 'L__self___transformer_h_11_mlp_c_fc.bias', 'L__self___transformer_h_11_mlp_c_proj.weight', 'L__self___transformer_h_11_mlp_c_proj.bias', 'L__self___lm_head.weight'], buffers=['L__self___transformer_h_0_attn_bias', 'L__self___transformer_h_1_attn_bias', 'L__self___transformer_h_2_attn_bias', 'L__self___transformer_h_3_attn_bias', 'L__self___transformer_h_4_attn_bias', 'L__self___transformer_h_5_attn_bias', 'L__self___transformer_h_6_attn_bias', 'L__self___transformer_h_7_attn_bias', 'L__self___transformer_h_8_attn_bias', 'L__self___transformer_h_9_attn_bias', 'L__self___transformer_h_10_attn_bias', 'L__self___transformer_h_11_attn_bias'], user_inputs=['arg161_1'], user_outputs=['view_217'], inputs_to_parameters={'arg0_1': 'L__self___transformer_h_0_ln_1_weight', 'arg1_1': 'L__self___transformer_h_0_ln_1_bias', 'arg2_1': 'L__self___transformer_h_0_ln_2_weight', 'arg3_1': 'L__self___transformer_h_0_ln_2_bias', 'arg4_1': 'L__self___transformer_h_1_ln_1_weight', 'arg5_1': 'L__self___transformer_h_1_ln_1_bias', 'arg6_1': 'L__self___transformer_h_1_ln_2_weight', 'arg7_1': 'L__self___transformer_h_1_ln_2_bias', 'arg8_1': 'L__self___transformer_h_2_ln_1_weight', 'arg9_1': 'L__self___transformer_h_2_ln_1_bias', 'arg10_1': 'L__self___transformer_h_2_ln_2_weight', 'arg11_1': 'L__self___transformer_h_2_ln_2_bias', 'arg12_1': 'L__self___transformer_h_3_ln_1_weight', 'arg13_1': 'L__self___transformer_h_3_ln_1_bias', 'arg14_1': 'L__self___transformer_h_3_ln_2_weight', 'arg15_1': 'L__self___transformer_h_3_ln_2_bias', 'arg16_1': 'L__self___transformer_h_4_ln_1_weight', 'arg17_1': 'L__self___transformer_h_4_ln_1_bias', 'arg18_1': 'L__self___transformer_h_4_ln_2_weight', 'arg19_1': 'L__self___transformer_h_4_ln_2_bias', 'arg20_1': 'L__self___transformer_h_5_ln_1_weight', 'arg21_1': 'L__self___transformer_h_5_ln_1_bias', 'arg22_1': 'L__self___transformer_h_5_ln_2_weight', 'arg23_1': 'L__self___transformer_h_5_ln_2_bias', 'arg24_1': 'L__self___transformer_h_6_ln_1_weight', 'arg25_1': 'L__self___transformer_h_6_ln_1_bias', 'arg26_1': 'L__self___transformer_h_6_ln_2_weight', 'arg27_1': 'L__self___transformer_h_6_ln_2_bias', 'arg28_1': 'L__self___transformer_h_7_ln_1_weight', 'arg29_1': 'L__self___transformer_h_7_ln_1_bias', 'arg30_1': 'L__self___transformer_h_7_ln_2_weight', 'arg31_1': 'L__self___transformer_h_7_ln_2_bias', 'arg32_1': 'L__self___transformer_h_8_ln_1_weight', 'arg33_1': 'L__self___transformer_h_8_ln_1_bias', 'arg34_1': 'L__self___transformer_h_8_ln_2_weight', 'arg35_1': 'L__self___transformer_h_8_ln_2_bias', 'arg36_1': 'L__self___transformer_h_9_ln_1_weight', 'arg37_1': 'L__self___transformer_h_9_ln_1_bias', 'arg38_1': 'L__self___transformer_h_9_ln_2_weight', 'arg39_1': 'L__self___transformer_h_9_ln_2_bias', 'arg40_1': 'L__self___transformer_h_10_ln_1_weight', 'arg41_1': 'L__self___transformer_h_10_ln_1_bias', 'arg42_1': 'L__self___transformer_h_10_ln_2_weight', 'arg43_1': 'L__self___transformer_h_10_ln_2_bias', 'arg44_1': 'L__self___transformer_h_11_ln_1_weight', 'arg45_1': 'L__self___transformer_h_11_ln_1_bias', 'arg46_1': 'L__self___transformer_h_11_ln_2_weight', 'arg47_1': 'L__self___transformer_h_11_ln_2_bias', 'arg48_1': 'L__self___transformer_ln_f_weight', 'arg49_1': 'L__self___transformer_ln_f_bias', 'arg50_1': 'L__self___transformer_wte.weight', 'arg51_1': 'L__self___transformer_wpe.weight', 'arg52_1': 'L__self___transformer_h_0_attn_c_attn.weight', 'arg53_1': 'L__self___transformer_h_0_attn_c_attn.bias', 'arg54_1': 'L__self___transformer_h_0_attn_c_proj.weight', 'arg55_1': 'L__self___transformer_h_0_attn_c_proj.bias', 'arg56_1': 'L__self___transformer_h_0_mlp_c_fc.weight', 'arg57_1': 'L__self___transformer_h_0_mlp_c_fc.bias', 'arg58_1': 'L__self___transformer_h_0_mlp_c_proj.weight', 'arg59_1': 'L__self___transformer_h_0_mlp_c_proj.bias', 'arg60_1': 'L__self___transformer_h_1_attn_c_attn.weight', 'arg61_1': 'L__self___transformer_h_1_attn_c_attn.bias', 'arg62_1': 'L__self___transformer_h_1_attn_c_proj.weight', 'arg63_1': 'L__self___transformer_h_1_attn_c_proj.bias', 'arg64_1': 'L__self___transformer_h_1_mlp_c_fc.weight', 'arg65_1': 'L__self___transformer_h_1_mlp_c_fc.bias', 'arg66_1': 'L__self___transformer_h_1_mlp_c_proj.weight', 'arg67_1': 'L__self___transformer_h_1_mlp_c_proj.bias', 'arg68_1': 'L__self___transformer_h_2_attn_c_attn.weight', 'arg69_1': 'L__self___transformer_h_2_attn_c_attn.bias', 'arg70_1': 'L__self___transformer_h_2_attn_c_proj.weight', 'arg71_1': 'L__self___transformer_h_2_attn_c_proj.bias', 'arg72_1': 'L__self___transformer_h_2_mlp_c_fc.weight', 'arg73_1': 'L__self___transformer_h_2_mlp_c_fc.bias', 'arg74_1': 'L__self___transformer_h_2_mlp_c_proj.weight', 'arg75_1': 'L__self___transformer_h_2_mlp_c_proj.bias', 'arg76_1': 'L__self___transformer_h_3_attn_c_attn.weight', 'arg77_1': 'L__self___transformer_h_3_attn_c_attn.bias', 'arg78_1': 'L__self___transformer_h_3_attn_c_proj.weight', 'arg79_1': 'L__self___transformer_h_3_attn_c_proj.bias', 'arg80_1': 'L__self___transformer_h_3_mlp_c_fc.weight', 'arg81_1': 'L__self___transformer_h_3_mlp_c_fc.bias', 'arg82_1': 'L__self___transformer_h_3_mlp_c_proj.weight', 'arg83_1': 'L__self___transformer_h_3_mlp_c_proj.bias', 'arg84_1': 'L__self___transformer_h_4_attn_c_attn.weight', 'arg85_1': 'L__self___transformer_h_4_attn_c_attn.bias', 'arg86_1': 'L__self___transformer_h_4_attn_c_proj.weight', 'arg87_1': 'L__self___transformer_h_4_attn_c_proj.bias', 'arg88_1': 'L__self___transformer_h_4_mlp_c_fc.weight', 'arg89_1': 'L__self___transformer_h_4_mlp_c_fc.bias', 'arg90_1': 'L__self___transformer_h_4_mlp_c_proj.weight', 'arg91_1': 'L__self___transformer_h_4_mlp_c_proj.bias', 'arg92_1': 'L__self___transformer_h_5_attn_c_attn.weight', 'arg93_1': 'L__self___transformer_h_5_attn_c_attn.bias', 'arg94_1': 'L__self___transformer_h_5_attn_c_proj.weight', 'arg95_1': 'L__self___transformer_h_5_attn_c_proj.bias', 'arg96_1': 'L__self___transformer_h_5_mlp_c_fc.weight', 'arg97_1': 'L__self___transformer_h_5_mlp_c_fc.bias', 'arg98_1': 'L__self___transformer_h_5_mlp_c_proj.weight', 'arg99_1': 'L__self___transformer_h_5_mlp_c_proj.bias', 'arg100_1': 'L__self___transformer_h_6_attn_c_attn.weight', 'arg101_1': 'L__self___transformer_h_6_attn_c_attn.bias', 'arg102_1': 'L__self___transformer_h_6_attn_c_proj.weight', 'arg103_1': 'L__self___transformer_h_6_attn_c_proj.bias', 'arg104_1': 'L__self___transformer_h_6_mlp_c_fc.weight', 'arg105_1': 'L__self___transformer_h_6_mlp_c_fc.bias', 'arg106_1': 'L__self___transformer_h_6_mlp_c_proj.weight', 'arg107_1': 'L__self___transformer_h_6_mlp_c_proj.bias', 'arg108_1': 'L__self___transformer_h_7_attn_c_attn.weight', 'arg109_1': 'L__self___transformer_h_7_attn_c_attn.bias', 'arg110_1': 'L__self___transformer_h_7_attn_c_proj.weight', 'arg111_1': 'L__self___transformer_h_7_attn_c_proj.bias', 'arg112_1': 'L__self___transformer_h_7_mlp_c_fc.weight', 'arg113_1': 'L__self___transformer_h_7_mlp_c_fc.bias', 'arg114_1': 'L__self___transformer_h_7_mlp_c_proj.weight', 'arg115_1': 'L__self___transformer_h_7_mlp_c_proj.bias', 'arg116_1': 'L__self___transformer_h_8_attn_c_attn.weight', 'arg117_1': 'L__self___transformer_h_8_attn_c_attn.bias', 'arg118_1': 'L__self___transformer_h_8_attn_c_proj.weight', 'arg119_1': 'L__self___transformer_h_8_attn_c_proj.bias', 'arg120_1': 'L__self___transformer_h_8_mlp_c_fc.weight', 'arg121_1': 'L__self___transformer_h_8_mlp_c_fc.bias', 'arg122_1': 'L__self___transformer_h_8_mlp_c_proj.weight', 'arg123_1': 'L__self___transformer_h_8_mlp_c_proj.bias', 'arg124_1': 'L__self___transformer_h_9_attn_c_attn.weight', 'arg125_1': 'L__self___transformer_h_9_attn_c_attn.bias', 'arg126_1': 'L__self___transformer_h_9_attn_c_proj.weight', 'arg127_1': 'L__self___transformer_h_9_attn_c_proj.bias', 'arg128_1': 'L__self___transformer_h_9_mlp_c_fc.weight', 'arg129_1': 'L__self___transformer_h_9_mlp_c_fc.bias', 'arg130_1': 'L__self___transformer_h_9_mlp_c_proj.weight', 'arg131_1': 'L__self___transformer_h_9_mlp_c_proj.bias', 'arg132_1': 'L__self___transformer_h_10_attn_c_attn.weight', 'arg133_1': 'L__self___transformer_h_10_attn_c_attn.bias', 'arg134_1': 'L__self___transformer_h_10_attn_c_proj.weight', 'arg135_1': 'L__self___transformer_h_10_attn_c_proj.bias', 'arg136_1': 'L__self___transformer_h_10_mlp_c_fc.weight', 'arg137_1': 'L__self___transformer_h_10_mlp_c_fc.bias', 'arg138_1': 'L__self___transformer_h_10_mlp_c_proj.weight', 'arg139_1': 'L__self___transformer_h_10_mlp_c_proj.bias', 'arg140_1': 'L__self___transformer_h_11_attn_c_attn.weight', 'arg141_1': 'L__self___transformer_h_11_attn_c_attn.bias', 'arg142_1': 'L__self___transformer_h_11_attn_c_proj.weight', 'arg143_1': 'L__self___transformer_h_11_attn_c_proj.bias', 'arg144_1': 'L__self___transformer_h_11_mlp_c_fc.weight', 'arg145_1': 'L__self___transformer_h_11_mlp_c_fc.bias', 'arg146_1': 'L__self___transformer_h_11_mlp_c_proj.weight', 'arg147_1': 'L__self___transformer_h_11_mlp_c_proj.bias', 'arg148_1': 'L__self___lm_head.weight'}, inputs_to_buffers={'arg149_1': 'L__self___transformer_h_0_attn_bias', 'arg150_1': 'L__self___transformer_h_1_attn_bias', 'arg151_1': 'L__self___transformer_h_2_attn_bias', 'arg152_1': 'L__self___transformer_h_3_attn_bias', 'arg153_1': 'L__self___transformer_h_4_attn_bias', 'arg154_1': 'L__self___transformer_h_5_attn_bias', 'arg155_1': 'L__self___transformer_h_6_attn_bias', 'arg156_1': 'L__self___transformer_h_7_attn_bias', 'arg157_1': 'L__self___transformer_h_8_attn_bias', 'arg158_1': 'L__self___transformer_h_9_attn_bias', 'arg159_1': 'L__self___transformer_h_10_attn_bias', 'arg160_1': 'L__self___transformer_h_11_attn_bias'}, buffers_to_mutate={}, backward_signature=None, assertion_dep_token=None)\n",
      "Symbol to range: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exported = export(gpt, args=(gpt_input,))\n",
    "print(exported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc67aa33-b646-4f1b-8e8c-4d0156a63d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting FLOPs for the exported graph...\n",
      "Number of nodes in the exported graph: 887\n",
      "Tracking operations ['aten::bmm', 'aten::addmm', 'aten::mm']\n",
      "All operations seen: ['aten::add.Tensor', 'aten::addmm', 'aten::where.self', 'aten::view', 'aten::permute', 'aten::lift_fresh_copy', 'aten::embedding', 'aten::clone', 'aten::bmm', 'aten::split.Tensor', 'aten::mul.Tensor', 'aten::slice.Tensor', 'aten::mm', 'aten::eq.Scalar', 'aten::gelu', 'aten::_softmax', 'aten::arange.start_step', 'aten::expand', 'aten::scalar_tensor', 'aten::index.Tensor', 'aten::native_layer_norm']\n",
      "\n",
      "FLOPs by Operation Type:\n",
      "aten::addmm: 173946175488 FLOPs (81.7885%)\n",
      "aten::bmm: 38654705664 FLOPs (18.1752%)\n",
      "aten::mm: 77266944 FLOPs (0.0363%)\n",
      "\n",
      "Total FLOPs: 212678148096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "212678148096"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops_report(exported)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e4446-08df-40c6-8ca8-2b1a39c626ab",
   "metadata": {},
   "source": [
    "Delve into the FLOPs for a Block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "943f8598-605a-4c9a-b493-05bcf9e5d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n"
     ]
    }
   ],
   "source": [
    "b = Block(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "82948a48-9c45-4876-a703-f43f784dbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = torch.randn(1, 1024, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "897cda97-4041-4df0-94b5-eff95bf94166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting FLOPs for the exported graph...\n",
      "Number of nodes in the exported graph: 74\n",
      "Tracking operations ['aten::bmm', 'aten::addmm', 'aten::mm']\n",
      "All operations seen: ['aten::bmm', 'aten::eq.Scalar', 'aten::add.Tensor', 'aten::_softmax', 'aten::gelu', 'aten::split.Tensor', 'aten::addmm', 'aten::where.self', 'aten::view', 'aten::permute', 'aten::expand', 'aten::mul.Tensor', 'aten::scalar_tensor', 'aten::slice.Tensor', 'aten::clone', 'aten::native_layer_norm']\n",
      "\n",
      "FLOPs by Operation Type:\n",
      "aten::addmm: 14495514624 FLOPs (81.8182%)\n",
      "aten::bmm: 3221225472 FLOPs (18.1818%)\n",
      "\n",
      "Total FLOPs: 17716740096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17716740096"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops_report(export(b, args=(arg,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572e8290-563b-4d0b-812f-14f2260ff739",
   "metadata": {},
   "source": [
    "FLOPs for LM head. Shapes taken from graph. 1 is there because in inference we only care about the final time dimension.\n",
    "\n",
    "f32[1, 768]\n",
    "f32[768, 50304]\n",
    "2 * 1 * 768 * 50304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ccc13bc5-0ca2-40bc-b5d6-1d51f7f512a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212678148096"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(17716740096 * 12) + (2 * 1 * 768 * 50304)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d0f73564-df7a-4a07-ad13-17a8e832762d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291722231808"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(17716740096 * 12) + (2 * 1024 * 768 * 50304) # for training (1024 is entire sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "44495dc9-a985-4a9c-ba17-26f9fc9a06ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77266944"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * 1 * 768 * 50304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "212b9312-0700-46e1-b568-21f8fe09924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(212678148096 - 212678148096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3fe5b0-9ae8-4d67-808f-086e469479e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
